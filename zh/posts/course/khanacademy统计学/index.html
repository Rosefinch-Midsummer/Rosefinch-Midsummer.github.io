<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>KhanAcademy《统计学》 | 天漢帝國復興錄</title><meta name=keywords content="统计学"><meta name=description content="在线计算器和解决数学问题
1均值、中位数、众数
均值mean、中位数median、众数mode
2极差、中程数
极差range、中程数mid-range
中程数是最大值和最小值的平均数。
3象形统计图
用符号表示数据类型，比如一滴血代表8个人，在统计图中画血的符号。"><meta name=author content="RM"><link rel=canonical href=https://rosefinch-midsummer.github.io/zh/posts/course/khanacademy%E7%BB%9F%E8%AE%A1%E5%AD%A6/><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><meta name=referrer content="no-referrer-when-downgrade"><link crossorigin=anonymous href=/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://rosefinch-midsummer.github.io/img/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://rosefinch-midsummer.github.io/img/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://rosefinch-midsummer.github.io/img/favicon-32x32.png><link rel=apple-touch-icon href=https://rosefinch-midsummer.github.io/img/apple-touch-icon.png><link rel=mask-icon href=https://rosefinch-midsummer.github.io/img/android-chrome-192x192.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://rosefinch-midsummer.github.io/zh/posts/course/khanacademy%E7%BB%9F%E8%AE%A1%E5%AD%A6/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><meta property="og:url" content="https://rosefinch-midsummer.github.io/zh/posts/course/khanacademy%E7%BB%9F%E8%AE%A1%E5%AD%A6/"><meta property="og:site_name" content="天漢帝國復興錄"><meta property="og:title" content="KhanAcademy《统计学》"><meta property="og:description" content="在线计算器和解决数学问题
1均值、中位数、众数 均值mean、中位数median、众数mode
2极差、中程数 极差range、中程数mid-range
中程数是最大值和最小值的平均数。
3象形统计图 用符号表示数据类型，比如一滴血代表8个人，在统计图中画血的符号。"><meta property="og:locale" content="zh"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-07-27T11:34:25+08:00"><meta property="article:modified_time" content="2025-10-20T21:28:22+08:00"><meta property="article:tag" content="统计学"><meta name=twitter:card content="summary"><meta name=twitter:title content="KhanAcademy《统计学》"><meta name=twitter:description content="在线计算器和解决数学问题
1均值、中位数、众数
均值mean、中位数median、众数mode
2极差、中程数
极差range、中程数mid-range
中程数是最大值和最小值的平均数。
3象形统计图
用符号表示数据类型，比如一滴血代表8个人，在统计图中画血的符号。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"📚文章","item":"https://rosefinch-midsummer.github.io/zh/posts/"},{"@type":"ListItem","position":2,"name":"🏫課程","item":"https://rosefinch-midsummer.github.io/zh/posts/course/"},{"@type":"ListItem","position":3,"name":"KhanAcademy《统计学》","item":"https://rosefinch-midsummer.github.io/zh/posts/course/khanacademy%E7%BB%9F%E8%AE%A1%E5%AD%A6/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"KhanAcademy《统计学》","name":"KhanAcademy《统计学》","description":"在线计算器和解决数学问题\n1均值、中位数、众数 均值mean、中位数median、众数mode\n2极差、中程数 极差range、中程数mid-range\n中程数是最大值和最小值的平均数。\n3象形统计图 用符号表示数据类型，比如一滴血代表8个人，在统计图中画血的符号。\n","keywords":["统计学"],"articleBody":"在线计算器和解决数学问题\n1均值、中位数、众数 均值mean、中位数median、众数mode\n2极差、中程数 极差range、中程数mid-range\n中程数是最大值和最小值的平均数。\n3象形统计图 用符号表示数据类型，比如一滴血代表8个人，在统计图中画血的符号。\n4条形图 bar graph\n将事物进行分类，并看每一类分别的怎样的情况\n5折线图 line graph\n反映变化趋势\n6饼图 pie graph\n看各部分的占比\n7误导人的折线图 8茎叶图 stem-and-leaf plot\n9箱线图 box-and-whiskers plot\n看数据的散布情况和中位数\n先求中位数，然后以中位数为界求前后两段的中位数作为四分位数\n10箱线图2 11统计：集中趋势 Statistics分为描述性统计学DescriptiveStatistics和推断统计学InferentialStatistics\nCentral Tendency通常用算数平均数、中位数、众数表示。\n12统计：样本和总体 样本sample\n总体population\n样本均值$\\bar x$\n总体均值$\\mu$\n13统计：总体方差 离散程度dispersion\n0 0 5 5和2 2 3 3的平均数相同\n总体方差$\\sigma^2=\\frac{\\sum_{i=1}^N(x_i-\\mu)^2}{N}$\n14统计：样本方差 样本方差$\\sigma^2=\\frac{\\sum_{i=1}^n(x_i-\\bar x)^2}{n}$\n样本方差$\\sigma^2=\\frac{\\sum_{i=1}^n(x_i-\\bar x)^2}{n}\\leq总体方差\\sigma^2=\\frac{\\sum_{i=1}^n(x_i-\\mu)^2}{n}$\n总体方差的无偏估计（unbiased estimate of the population variance）或称之为无偏样本方差（unbiased sample variance）\n方差$\\sigma^2=\\frac{\\sum_{i=1}^n(x_i-\\bar x)^2}{n-1}$\n15统计：标准差 standard deviation标准差的单位更好\n16统计：诸方差公式 总体方差$\\sigma^2=\\frac{\\sum_{i=1}^N(x_i-\\mu)^2}{N}$可化为$\\sigma^2=\\frac{\\sum_{i=1}^Nx_i^2}{N}-\\mu^2$\n17随机变量介绍 random variable一般用大写字母表示，随机变量实际上是一种函数——将random process随机过程映射到实际数字的函数。如抛硬币过程：\n$$X= \\begin{cases} 1,\u0026if hats\\ 0,\u0026if tails \\end{cases} $$\n随机变量分为连续型continuous随机变量和离散型discrete随机变量。\n18概率密度函数 离散型随机变量有概率分布函数（probability distribution function）\n连续型随机变量有概率密度函数（probability density function）\n19二项分布1 binomial probability distribution\n二项分布是n重伯努利试验成功次数的离散概率分布，X服从二项分布记作X~B(n,p)，伯努利试验是只有两种可能结果的单次随机试验。\n进行伯努利试验，成功（X=1）概率为p，失败（X=0）概率为1-p，随机变量X服从伯努利分布。\n两点分布或称之为0-1分布\n随机变量X 1 0 概率P p 1-p 20二项分布2 21二项分布3 22二项分布4 23期望值E(x) 期望值就是总体均值。\n24二项分布的期望值 二项分布就是一堆两点分布。\nE(x)=np\nD(x)=np(1-p)\n期望值就是这些经过概率加权之后的和。\n25泊松过程1 Poisson Distribution泊松分布其实来自二项分布。\n泊松分布适用于描述单位时间/空间内随机事件发生的次数。\n泊松分布的使用场景，需要满足下面三个条件：\n单个事件发生与否，及发生概率是独立的； 已知给定区间（时间/空间）内，事件平均发生次数（发生率）； 发生的次数是有限的。 26泊松过程2 # 离散型概率分布——泊松分布\n公式：假设K为给定区间内时间/空间的发生次数。参数λ为每个区间内平均发生次数 。概率可用公式表示如下：\n$P(X=k)=\\frac{e^{-\\lambda}\\lambda^k}{k!}$\n推导过程需要用到第二个重要极限。\n示例：一个售后服务中心，平均每周接到A项目投诉2.5次。求下周没有接到A项目的投诉的概率是多少，接到A项目投诉3次的概率是多少。\n泊松分布求期望和方差非常好记，都为λ。\n泊松分布求期望： 公式：如果X~po(λ)，那么E(x)=λ。\n示例：沿用上述A项目投诉的例子，在一周之内预计发生A项目的投诉次数为2.5次。\n泊松分布求方差： 公式：如果X~po(λ)，那么Var(x)=λ。\n示例：沿用上述A项目投诉的例子，在一周之内预计发生A项目的投诉次数的方差为2.5次。\n组合泊松分布： 公式：如果Xpo(λx)，且如果Ypo(λy)，则：X +Y ~ po(λx+λy)\n示例：该售后服务中心，除了平均每周接到A项目的投诉2.5次，还会接到平均每周1次的B项目的投诉。下周总部会下来调查，希望收到的总投诉次数为0次，求这种情况的概率。\n由结果可知，下周零投诉的概率为0.03。\n次数过多的二项分布使用泊松分布求解： 之前在分享二项分布的时候，大家是否还记得猜箱子的小游戏？这个小游戏一共由4道题目组成，那么，假若这个小游戏有100道题目，甚至1000道题目呢？光是计算组合公式会让你算到头大。\n其实在遇到这种情况时，泊松分布也可以帮上忙。那么先来回顾下二项分布的期望与方差。\n二项分布的期望E(r)=np，方差Var(r)=npq，而泊松分布的期望和方差均为λ。此时我们需要这两种分布的期望和方差相近似，即np与npq近似相等的情况 。\n由以上可知，当二项分布的n很大而p很小时，泊松分布可作为二项分布的近似，其中λ为np。通常当n≥20，p≤0.05时，就可以用泊松公式近似得计算。\n示例：借用二项分布文章中打靶的例子，假设打靶的数量为100次，求在这100次打靶中有3次能够打中10环的概率是多少 。\n在本题中，n=100，p=0.05，np=5，使用二项分布的泊松分布近似法得到X~po(5)，代入公式求出概率：\n所以100次打靶中3次命中10环的概率为0.14。\n27大数定律 The law of large numbers\n样本量足够大时，样本均值接近期望值\n赌徒谬误gambler’s fallacy：一定次数试验后，如果正面数高于均值，则大数定律会让后面的正面数更少。\n大数定律不关心前面发生的情况，收敛于期望值只是因为还有无限次收敛于期望值的试验，让前面的有限次实验可以忽略。不过买彩票和赌博的人并没有遵循这个原则。赌徒们不遵循这一原则，但赌场是知道的。短期内，少量样本时，有些人能打败庄家，但长期来看，庄家肯定是赢的，因为赌局的参数是他们定的。\n28正态分布Excel练习 正态分布可以通过二项分布近似很好地得到。\ncentral limit theorem中心极限定理即随机变量和的分布以正态分布为极限，即使这些试验的分布不是正态的。\n29正态分布介绍 概率密度函数$p(x)=\\frac{1}{\\sigma \\sqrt{2\\pi}}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})=\\frac{1}{\\sqrt{2\\pi\\sigma^2exp(z^2)}}$，其中标准z分数$z=\\frac{x-\\mu}{\\sigma}$\n概率就是对概率密度函数求定积分。\n30正态分布问题：哪些是正态分布？ 31正态分布问题：z分数 z score就是离均值有多少个标准差远\n32正态分布问题：经验法则 empirical rule经验法则\n高斯分布曲线取决于两个因素，即均值和标准差。分布的均值决定了图形中心位置，标准差决定了图像的高度与宽度，标准差小时，曲线“高瘦”，标准差大时，曲线“矮胖”。\nsigma原则：数值分布在（μ-σ，μ+σ）中的概率为0.6526；\n2sigma原则：数值分布在（μ-2σ，μ+2σ）中的概率为0.9544；\n3sigma原则：数值分布在（μ-3σ，μ+3σ）中的概率为0.9974；\n基本上可以把区间（μ-3σ,μ+3σ）看作是随机变量X实际可能的取值区间，落在该区间之外的概率小于千分之三。\n33练习：标准正态分布和经验法则 standard normal distribution X~N(0,1)\n34经验法则和z分数的进一步练习 AP统计考试分数不是正态分布，有$\\sigma和\\mu$能求近似z-score。\nz-score就是离均值有多少个标准差远，可以用在任何分布上，只要知道均值和标准差。\n35中心极限定理 # 中心极限定理——概率论中最重要的结论之一\n随着样本容量sample size趋于$\\infty$，离散随机变量分布会趋于正态分布。\n中心极限定理（central limit theorem/CLT）是概率论（probability theory）一个非常重要的结论，它指出在一定条件下，独立（independent）随机变量的标准化的（normalized）和随样本量（sample size）变大会趋向正态分布（normal distribution），即它的累积分布函数（cumulative distribution function/CDF）会收敛于标准正态分布（standard normal distribution）的CDF $N(x)=\\int_{-\\infty}^{x}\\frac{1}{\\sqrt{2\\pi}}e^\\frac{-x^2}{2}dx$\n中心极限定理不要求随机变量本身是正态分布的，所以它带来一个非常重要的结果：在一定条件下，我们可以使用对正态分布成立的方法去应对非正态分布。比如，对于样本量 � 足够大时，二项分布（binomial distribution）$Bin(n,p)$ 可以用正态分布$N(np, np(1-p))$ 来近似。用具体事例来表达，如果我们抛 500 次硬币，由于每次抛硬币正面朝上的概率为 12 ，我们可以将正面朝上的数量近似地视作一个 $N(250,125)$ 的随机变量。中心极限定理有很多种版本，也有对于非独立变量的变式。在本篇文章中，我们将要介绍对于独立变量的中心极限定理的三个版本。有经典中心极限定理、林德伯格中心极限定理、李雅普诺夫中心极限定理、多维中心极限定理几种。\n36样本均值的抽样分布 Online Statistics Education: An Interactive Multimedia Course of Study\nsampling distribution of the sample mean\n# 偏度和峰度\n完美正态分布的偏度skew是0。如果偏度为正，意味着右侧尾部较长，即均值向左偏。\n峰度kurtosis\n正峰度——高\n偏度 偏度（Skewness）可以用来度量随机变量概率分布的不对称性。\n公式：\n$S=\\frac{1}{n}\\sum_{i=1}^n [(\\frac{X_i-\\mu}{\\sigma})^3]$\n其中 $\\mu$ 是均值， $\\sigma$是标准差。\n计算例子：\n一组数据为1、2、2、4、1，均值为2，标准差约为1.22，所以偏度为\n$S=15×[(1−21.22)^3+(2−21.22)^3+…+(1−21.22)^3]≈1.36$\n几何意义：\n偏度的取值范围为(-∞,+∞)\n当偏度\u003c0时，概率分布图左偏。\n当偏度=0时，表示数据相对均匀的分布在平均值两侧，不一定是绝对的对称分布。\n当偏度\u003e0时，概率分布图右偏。\n例如上图中，两个概率分布图都是均值=0.6923，标准差=0.1685的，但是他们的形状是不一样的，左图偏度=-0.537，形状左偏，右图偏度=0.537，形状右偏。\n峰度 峰度（Kurtosis）可以用来度量随机变量概率分布的陡峭程度。\n公式：\n$K=\\frac{1}{n}\\sum_{i=1}^n [(\\frac{X_i-\\mu}{\\sigma})^4]$\n其中 $\\mu$ 是均值， $\\sigma$是标准差。\n几何意义：\n峰度的取值范围为[1,+∞)，完全服从正态分布的数据的峰度值为 3，峰度值越大，概率分布图越高尖，峰度值越小，越矮胖。\n例如上图中，左图是标准正态分布，峰度=3，右图的峰度=4，可以看到右图比左图更高尖。\n通常我们将峰度值减去3，也被称为超值峰度（Excess Kurtosis），这样正态分布的峰度值等于0，当峰度值\u003e0，则表示该数据分布与正态分布相比较为高尖，当峰度值\u003c0，则表示该数据分布与正态分布相比较为矮胖。\n37样本均值的抽样分布2 随着样本容量增大，分布会怎么变化？\n当$n-\u003e\\infty$时样本均值的抽样分布变为正态分布。一般来说，n=10或15就已经很接近正态分布了。\n38均值标准误差 标准差standard deviation也被称为标准偏差，是描述各数据偏离平均数的距离的平均数，表征的是数据的离散程度。\n标准误差Standard error表征的是单个统计量在多次抽样中呈现出的变异性。\n前者表示数据本身的变异性，后者表征的是抽样行为的变异性。\n随着样本容量的增大，会发生两件事：一是更接近正态分布，二是标准差更小。\n样本均值抽样分布的方差等于原分布的方差除以n即$\\sigma^2_{\\bar x}=\\frac{\\sigma^2}{n}$\n标准误差等于原分布标准差除以根号n即$\\sigma_{\\bar x}=\\frac{\\sigma}{\\sqrt n}$\n39抽样分布例题 The average male drinks 2L of water when active outdoors (with a standard deviation of .7L). You are planning a full day nature trip for 50 men and will bring 110L of water. What is the probability that you will run out?\nP(run out) = P(usr more than 110L) = P(average water use per man is \u003e 2.2L/m)\nSampling distribution of the sample mean when n=50\n$\\mu_{\\bar x}=\\mu=2L$\n$\\sigma_{\\bar x}=\\frac{\\sigma}{\\sqrt n}=\\frac{0.7}{\\sqrt 50}=0.099$\n$z-score=\\frac{X-\\mu}{\\sigma_{\\bar x}}=\\frac{2.2-2}{0.099}=2.02$\n水不够的概率即是样本均值大于均值右侧2.020个标准差处的概率，根据z表格来求低于某值的概率。\nP($\\bar x$ will be more than 2.022 standard deviation above the mean)=1-0.9783=0.0217=2.17%\n40置信区间 e.g. You sample 36 apples from your farm’s harvest of over 200,000 apples. The mean weight of the sample is 112grams(with a 40 gram sample standard deviation). What is the probability that the mean weight of all 200,000 apples is within 100 and 124 grams?\n即求总体均值落在样本均值左右12g范围内的概率。\nP($\\mu$ is within 12 of $\\bar X$)=P($\\bar X$ is within 12 of $\\mu$)\n重新写成这样之后，我们就会自然想到使用样本均值抽样分布。\nP($\\bar X$ is within 12 of $\\mu$)=P($\\bar X$ is within 12 of $\\mu_{\\bar x}$)\n即求某一特定样本均值落在抽样分布均值左右12g范围内的概率。\n$\\sigma_{\\bar x}=\\frac{\\sigma}{\\sqrt n}=\\frac{40}{\\sqrt 36}=6.67$\n$z-score=\\frac{X-\\mu}{\\sigma_{\\bar x}}=\\frac{12}{6.67}=1.8$\n根据z表格来求低于1.8个标准差的概率为0.9641。（这里只能从右边计算）\n所求概率$P=2*(0.9641-0.5)=0.9282$\n41伯努利分布均值和方差的例子 伯努利分布是两点分布。\n离散分布期望值是各种可能值概率加权后的和。\n支持与否 不支持0 支持1 概率 0.4 0.6 期望值=0.6\n方差=$0.4*(0-0.6)^2+0.6*(1-0.6)^2=0.4*0.6=0.24$\n42伯努利分布均值和方差的公式 $\\mu = p$\n$\\sigma^2 = (1-p)(0-p)^2+p(1-p)^2=p(1-p)$\n43误差范围1 随机调查100人的投票意愿，选B的（认为是事件1）有43人，选A的（认为是事件0）有57人。样本均值为0.43，方差为0.2475，样本标准差0.50，标准误差0.05。\n找到这样一个合理置信区间，95%确信总体真实均值p值落在其中的区间\n样本均值、抽样分布均值、总体均值是统计学中的重要概念，它们之间的区别如下：\n样本均值：是指从总体中随机抽取一个样本，并计算该样本中所有观测值的平均数。样本均值是对样本数据的一个统计描述，通常用作总体均值的估计值。\n抽样分布均值：是指从总体中抽取多个样本，并计算所有样本均值的平均数。抽样分布均值是对样本均值的分布的一个描述，它的均值通常等于总体均值。\n总体均值：是指总体中所有观测值的平均数。总体均值是一个未知参数，通常需要通过样本统计量来估计。\n总体均值是一个固定的未知参数，而样本均值和抽样分布均值是随机变量，它们的取值会随着不同的样本选择而变化。在统计学中，通过样本均值来估计总体均值是一种常见的方法，而抽样分布均值则用于评估样本均值的变异情况。\n44误差范围2 找出一个合理的置信区间，95%的几率确信总体真实均值$\\mu=p=\\mu_{\\bar x}$落在其中的区间\n在正态分布中，样本均值落在两个标准差范围内的概率是95.44%。\n抽样分布的均值等于原分布的均值。抽样分布标准差是标准误差，不是样本标准差。\n误差范围margin of error是另一种描述置信区间confidence interval的方式。\nP($\\bar X$ is within $2\\sigma_{\\bar x}$ of $\\mu_{\\bar X}$)=95.4% P(p is within $2\\sigma_{\\bar x}$ of $\\bar X$)=95.4% P(p is with 2(0.05) of $\\bar X$)=95%（从这里开始往下都是约等号） P(p is with 2(0.05) of $\\bar X$)=95% P(p is with 0.1 of $\\bar X$)=95% P(p is within 0.33~0.53)=95% 45置信区间例题 从6250名教师中随机抽取250人询问他们是否认为计算机是教室必备教学工具。其中，142名教师认为是必备的教学工具（记为事件1），108名教师认为不是必备的教学工具（记为事件0）。\n\\|X=1 X=0 P 0.568 0.432 均值为0.568，方差为0.246，样本标准差为0.496四舍五入为0.50，抽样分布标准差（标准误差）近似于样本标准差除以根号下样本容量，$\\sigma_{\\bar x}$=0.031\n注：用p(1-p)计算得到的方差为0.245\n1.Calculate a 99% confidence interval for the proportion of teachers who felt that computers are an essential teaching tool.\n$0.99/2=0.495$\n$0.495+0.5=0.995$\n查询z-table发现0.995对应的数值为2.58，即有大概99%的概率使得样本均值落在抽样分布均值左右2.58个标准差（对应的概率为99.02%）范围内。抽样分布均值也就是原分布的均值，也就是认为计算机必备的老师占比p。这个值未知，但它有一个不错的估计值。\n我们有99%的把握认为样本均值0.568落在概率p左右0.08范围内，也即有99%的把握认为概率p落在0.568左右0.08范围内。\n置信区间为0.488~0.648，我们相信有99%几率真实概率p在这里两个数字之间。\n2.How could the survey be changed to narrow the confidence interval but to maintain the 99% confidence interval?\n保持99%置信水平的前提下如何缩小置信区间？抽取更大样本即可。\n置信区间是指对于一个总体参数（比如总体均值或总体比例），基于样本数据，计算出的一个区间，使得该区间内包含该总体参数真实值的概率达到预先设定的置信水平。换句话说，置信区间是对总体参数真实值的一个估计，它告诉我们该估计的可靠程度。例如，假设我们想要估计某个产品的平均销售量。我们可以从该产品的销售记录中随机抽取一些样本，计算出样本均值和样本标准差。然后，我们可以使用样本均值和样本标准差，基于正态分布理论，计算出一个置信区间。例如，如果我们设置置信水平为95%，那么该置信区间将会包含95%的情况下真实的总体均值。这个区间的端点称为置信下限和置信上限。置信区间的宽度取决于样本大小、置信水平和总体标准差等因素。置信水平越高，置信区间就越宽；样本容量越大，置信区间就越窄；总体标准差越小，置信区间就越窄。置信区间是统计推断的重要工具，它可以帮助我们对总体参数的真实值做出合理的推断和决策。\n样本容量越大，抽样分布标准差就越小，置信区间通常就越窄。\n这是因为样本容量的增加会减小样本均值和总体均值之间的差异，从而使得置信区间变窄。具体而言，当样本容量增加时，样本均值的方差会减小，因此样本均值周围的误差也会减小，这就会导致置信区间的宽度减小。同时，当样本容量增加时，抽样分布的形状会趋近于正态分布，这也会使得置信区间变窄。需要注意的是，当总体标准差或置信水平固定时，样本容量越大，置信区间就越窄。但是，如果置信水平随样本容量的增加而提高，那么置信区间的变化可能会更加复杂。此外，当总体标准差未知时，使用样本标准差来计算置信区间时，样本容量的增加会使得样本标准差和抽样分布的自由度变化，这也需要考虑到。因此，总体标准差、置信水平、样本容量等因素的变化都会对置信区间的宽度产生影响，需要在实际问题中具体分析和判断。\n46小样本容量置信区间 样本容量\u003c30通常被认为是糟糕的估计。\n7个病人服药后血压分别上升了1.5, 2.9, 0.9, 3.9, 3.2, 2.1和1.9。Construct a 95% confidence interval for the true expected blood pressure increase for all patients in a population.\n均值为2.34，标准差为1.04，$\\sigma_{\\bar x}$=0.39\n这个视频里要讲的是，我们关注抽样分布，以此来生成区间。这里抽样分布不能像原来那样认为是正态分布使用中心极限定理之类的。我们需要改变抽样分布，不再假设是正态分布。我们假设是所谓的t分布。可以认为t分布是专门为更好估计小容量样本的置信区间所设计的。\nt分布是一种概率分布，通常用于在样本容量较小的情况下进行总体参数的推断。t分布由英国统计学家威廉·塞奇威克（William Sealy Gosset）于西元1908年提出，因此也被称为“塞奇威克t分布”。t分布的形状类似于正态分布，但是相比于正态分布，它的峰度较低，而且尾部较厚。这是因为t分布的概率密度函数是基于样本标准差来计算的，而样本标准差本身是一个不稳定的估计量，其方差会随着样本容量的减小而增加。因此，在样本容量较小的情况下，t分布的形状会更加扁平和宽，以保证在总体均值未知时，对样本均值的推断更加准确。t分布的参数是自由度（degrees of freedom，df），自由度是指用于计算样本标准差的样本数量减去1。自由度越大，t分布就越接近于正态分布。在实践中，t分布通常用于构建置信区间或进行假设检验，以便对总体参数进行推断。\n计算t分布的置信区间通常需要以下步骤：\n确定置信水平（confidence level）和自由度（degrees of freedom，df）。通常情况下，置信水平取值为95%或99%，自由度的计算方法取决于具体的问题，例如在单样本t检验中，自由度为n-1，其中n为样本容量。\n计算样本均值（sample mean）和样本标准差（sample standard deviation）。样本均值是指样本中所有观测值的平均数，样本标准差是指样本中所有观测值与样本均值的差的平方和的平均数的平方根。\n计算t值（t statistic）。t值是指样本均值与总体均值之间的差异除以标准误差（standard error）的比值，其中标准误差是指样本标准差除以样本容量的平方根。t值的计算公式为：\nt = (sample mean - population mean) / (sample standard deviation / sqrt(sample size))\n其中，sample mean为样本均值，population mean为总体均值，sample standard deviation为样本标准差，sample size为样本容量。\n根据置信水平和自由度，查找t分布表（或使用计算机软件）得到t临界值（t critical value）。\n计算置信区间。置信区间可以通过以下公式计算：\nconfidence interval = sample mean ± t临界值 × (sample standard deviation / sqrt(sample size))\n其中，sample mean为样本均值，t临界值为根据置信水平和自由度从t分布表或计算机软件中查找得到的t值，sample standard deviation为样本标准差，sample size为样本容量。\n通过以上步骤，可以得到t分布的置信区间，该区间表示总体参数的真实值有一定的概率落在该区间内。需要注意的是，计算t分布的置信区间时，需要满足一些假设条件，例如样本来自正态分布总体或样本容量较大等，否则计算结果可能不可靠。\n置信水平为95%，自由度为6，查询t表格（该分布关于中轴对称，所以叫双侧。单侧表示一直到特定值的累积百分比。本题是对称的，用two-sided。）此时对应两侧2.447个标准差。t表格中说的标准差是通过样本标准差得到的估计值。\n$\\sigma_{\\bar x}$=0.39，$\\sigma_{\\bar x}\\times 2.447=0.96$，置信区间为1.38~3.30\n说置信区间是因为这都是估计值。\n47假设检验和p值 假设检验需要两个假设，一个是原假设（null hypothesis），另一个是备择假设（alternative hypothesis）。\n原假设是一个被假定的基准假设，通常表示研究者想要测试的“无效”或“无差异”的情况。在进行假设检验时，我们会假定原假设为真，并通过数据来判断是否拒绝原假设。\n备择假设则是对原假设的补充或对立假设，通常表示研究者想要证明的“有效”或“有差异”的情况。如果拒绝原假设，则可以接受备择假设。\n因此，假设检验需要两个假设来进行比较和决策。通过比较数据与原假设的符合程度，我们可以判断是否有足够的证据来拒绝原假设，从而接受备择假设。\np值是指在假设检验中，根据样本数据计算出的一个概率值，表示在原假设为真的情况下，出现观测结果或更极端结果的概率。p值越小，代表观测到的数据与原假设不一致的可能性越大。\np值的主要作用是帮助我们做出关于原假设是否应被拒绝的决策。通常，我们会预先设定一个显著性水平（significance level）作为决策的标准，一般为0.05或0.01。如果计算出的p值小于显著性水平，则拒绝原假设，认为观测到的数据与原假设不一致；反之，则接受原假设。\n除了用于决策的作用，p值还可以提供一些定量的信息。例如，p值越小，代表观测到的数据与原假设的差异越明显，可能性越小；而p值越大，则表示观测到的数据与原假设的差异越小，可能性越大。\n需要注意的是，p值只能提供关于原假设是否应被拒绝的决策和一些定量信息，而不能确定原假设是否真实或备择假设是否正确。因此，在解释p值时，需要结合具体的实际背景和领域知识，进行综合分析。\n例：已知没有注射药物的老鼠平均反应时间是1.2秒，100只注射药物的老鼠的平均反应时间为1.05秒，样本标准差为0.5秒。药物对反应时间有影响吗？\n这里我们需要建立两个假设。\n第一个假设是原假设（null hypothesis） H0: 药物对反应时间没影响\n第二个假设是备择建设（alternative hypothesis）H：药物对反应时间有影响\n假设Ho为真，然后求样本均值1.05，标准差0.5这一结果的概率，如果这个概率特别小，则认为原假设为假。\n抽样分布均值=总体均值\n抽样分布标准差等于总体标准差除以根号下样本容量，而总体标准差近似于样本标准差。\nz-score = 3\n根据经验法则，均值左右3个标准差内的概率为99.7%。\n得到样本均值1.05，标准差0.5这一结果甚至更极端结果的概率为0.3%，这个概率特别小，因此我们认为原假设为假。\n很多论文中，得到零假设中这种极端情况甚至更极端情况的概率称为p值。本题中p值为0.003。\n48单侧检验和双侧检验 单侧检验和双侧检验是假设检验中常用的两种检验方式。\n单侧检验（one-tailed test）是指在假设检验中，备择假设只包含一个方向的偏差，例如只考虑检验均值是否大于某个特定值，或者只考虑检验均值是否小于某个特定值。单侧检验所关心的只是一个方向的差异，因此在计算p值时，只需要考虑备择假设的一个方向即可。\n双侧检验（two-tailed test）是指在假设检验中，备择假设包含两个方向的偏差，例如考虑检验均值是否与某个特定值不同，即既可能大于特定值，也可能小于特定值。双侧检验所关心的是两个方向的差异，因此在计算p值时，需要将备择假设的两个方向都考虑进去。\n在进行单侧检验或双侧检验时，需要根据具体的实际背景和研究问题来确定使用哪种检验方式。如果研究者只关心一个方向的差异，可以选择单侧检验；如果研究者关心两个方向的差异，需要选择双侧检验。此外，在进行假设检验时，还需要注意选择适当的显著性水平和合适的假设检验方法，以得到准确、可靠的结果。\n上题中我们只能说药物有一定效果，用药后的均值同原均值不一样，但没说增加还是减少了反应时间。\n检验是否存在效果，这是双侧检验。\n检验是否能减少平均反应时间，这是单侧检验。if H0, P(result lowers than 1.05s)=0.0015\n49z统计量VSt统计量 $z统计量=\\frac{\\bar X -\\mu_{\\bar X}}{\\frac{\\sigma}{\\sqrt n}} =\\frac{\\bar X -\\mu_{\\bar X}}{\\frac{S}{\\sqrt n}}$（正态分布、样本容量\u003e30）\n$t统计量=\\frac{\\bar X -\\mu_{\\bar X}}{\\frac{S}{\\sqrt n}}$（t分布、样本容量小）\n50 第一型错误 第一型错误（Type I error）是指在假设检验中，拒绝了原假设，但实际上原假设是正确的，也就是错误地认为存在某种差异或效应。第一型错误通常用α表示，也称为显著性水平。\n在假设检验中，我们需要设定一个显著性水平，通常为0.05或0.01，作为决策的标准。如果计算出的p值小于显著性水平，我们会拒绝原假设，认为观测到的数据与原假设不一致，也就是存在某种差异或效应。但如果实际上原假设是正确的，那么我们就会犯第一型错误，错误地认为存在差异或效应。\n第一型错误是假设检验中一个比较严重的错误，因为它会导致我们得出错误的结论，浪费研究资源，也可能对决策产生严重后果。因此，在进行假设检验时，需要设定适当的显著性水平，并根据具体实际情况进行综合分析，以减少第一型错误的概率。\n第一型错误和第二型错误是假设检验中两种不同类型的错误。\n第一型错误（Type I error）是指拒绝原假设，但实际上原假设是正确的，也就是错误地认为存在某种差异或效应。第一型错误的概率通常用α表示，也称为显著性水平。\n第二型错误（Type II error）是指接受原假设，但实际上原假设是错误的，也就是错误地认为不存在某种差异或效应。第二型错误的概率通常用β表示。\n可以看出，第一型错误和第二型错误的区别在于错误的方向不同。第一型错误是错误地拒绝了原假设，而第二型错误是错误地接受了原假设。\n在假设检验中，我们需要设定一个显著性水平作为决策的标准，以判断是否拒绝原假设。但在实际应用中，往往存在着一定的风险和成本，例如错失某种重要的差异或效应，或者浪费研究资源。因此，在进行假设检验时，需要综合考虑第一型错误和第二型错误，并选择适当的显著性水平和样本大小，以尽可能降低两种错误的概率。\n在假设检验中，设定显著性水平是做出决策的关键因素之一。通常，显著性水平设定为0.05或0.01，这表示在原假设为真的情况下，出现观测结果或更极端结果的概率不超过5%或1%。显著性水平越小，代表拒绝原假设的标准越高，对差异或效应的要求也越高，但可能会导致第二型错误的概率增加。\n设定显著性水平时，需要考虑具体的实际背景和研究问题，以及假设检验的目的和要求。如果研究对象是生命、财产等重大事项，或决策后果十分严重，需要设定更高的显著性水平，以尽可能降低第一型错误的概率；如果研究对象是对差异或效应的要求不高，或者样本量比较大，可以适当降低显著性水平，以降低第二型错误的概率。\n此外，还需要考虑假设检验的类型和样本大小等因素。例如，在单侧检验中，显著性水平需要分配给备择假设的一个方向；在样本量较小的情况下，需要设定更高的显著性水平，以尽可能避免漏诊。\n总之，设定显著性水平需要综合考虑各种因素，并根据具体情况进行灵活调整，以得到准确、可靠的假设检验结果。\n51小样本假设检验 例题：The mean emission of all engines of a new design needs to be below 20 ppm if the design is to meet new emission requirements. Ten engines are manufactured for testing purposes, and the emission level of each is determined. The emission data is :\n15.6 16.2 22.5 20.5 16.4 19.4 16.6 17.9 12.7 13.9\nDoes tje data supply sufficient evidence to conclude that this type of engine meets the new standard? Assume we are willing to risk a Type I error with probability = 0.01\n均值=17.17标准差为2.98\nH0：不满足标准$\\mu=20ppm$\nH1：满足标准即实际均值低于20ppm（$\\mu\u003c 20ppm$\n先认为原假设H0成立，如果样本均值得到17.17的概率小于1%，我们就拒绝原假设\n$t=\\frac{17.17-20}{\\frac{2.98}{\\sqrt 10}}=-3.00$\n由对称性，查表知单侧t临界值为-2.8214，即t值小于-2.8214的概率是1%。我们算出的t值是-3.00，这显然进入了让我们拒绝原假设的区域，t值得到-3.00的概率比1%还小，所以我们可以相对可靠地拒绝原假设，接受备择假设即满足排放标准。而且这里犯第一型错误的概率低于1%。\n52t统计量置信区间 计算t分布的置信区间通常需要以下步骤：\n确定置信水平（confidence level）和自由度（degrees of freedom，df）。通常情况下，置信水平取值为95%或99%，自由度的计算方法取决于具体的问题，例如在单样本t检验中，自由度为n-1，其中n为样本容量。\n计算样本均值（sample mean）和样本标准差（sample standard deviation）。样本均值是指样本中所有观测值的平均数，样本标准差是指样本中所有观测值与样本均值的差的平方和的平均数的平方根。\n计算t值（t statistic）。t值是指样本均值与总体均值之间的差异除以标准误差（standard error）的比值，其中标准误差是指样本标准差除以样本容量的平方根。t值的计算公式为：\nt = (sample mean - population mean) / (sample standard deviation / sqrt(sample size))\n其中，sample mean为样本均值，population mean为总体均值，sample standard deviation为样本标准差，sample size为样本容量。\n根据置信水平和自由度，查找t分布表（或使用计算机软件）得到t临界值（t critical value）。\n计算置信区间。置信区间可以通过以下公式计算：\nconfidence interval = sample mean ± t临界值 × (sample standard deviation / sqrt(sample size))\n其中，sample mean为样本均值，t临界值为根据置信水平和自由度从t分布表或计算机软件中查找得到的t值，sample standard deviation为样本标准差，sample size为样本容量。\n通过以上步骤，可以得到t分布的置信区间，该区间表示总体参数的真实值有一定的概率落在该区间内。需要注意的是，计算t分布的置信区间时，需要满足一些假设条件，例如样本来自正态分布总体或样本容量较大等，否则计算结果可能不可靠。\nt分布通常在样本容量较小的情况下使用。这是因为在小样本情况下，往往我们无法准确知道总体的标准差，所以我们使用样本标准差代替，这就引入了更多的不确定性，t分布就是在这种情况下用来估计未知总体均值的一种方法。但是，尽管t分布常常用于小样本量的情况，但也不是说在大样本量的情况下就不能使用。实际上，当样本量增大时，t分布会逐渐接近正态分布。所以，如果样本量较大，使用t分布和正态分布的结果差异通常很小，可以视为可忽略不计。另外，正如你所提到的，使用t分布需要满足一些前提假设，其中一个重要的假设是样本来自正态分布的总体。如果这个假设不满足，t分布可能就不是一个好的选择。\n总的来说，t分布是一个在特定情况下使用的工具，其适用性取决于样本大小、样本来源等因素。\n置信水平为95%，自由度为9，查询t表格（该分布关于中轴对称，所以叫双侧。单侧表示一直到特定值的累积百分比。本题是对称的，用two-sided。）此时对应两侧2.262个标准差。t表格中说的标准差是通过样本标准差得到的估计值。\n$\\sigma_{\\bar x}$=17.17，$\\sigma_{\\bar x}\\times 2.262=2.13$，置信区间为15.04~19.30\n说置信区间是因为这都是估计值。\n53大样本占比假设检验 例：We want to test the hypothesis that more than 30% of U.S. households have Internet access( with a significance level of 5%). We collect a sample of 150 households and find that 57 access.\n要进行假设检验，首先要设定零假设和备择建设。零假设也就是要检验的内容不正确，这里零假设是美国家庭总体的互联网接入率小于等于30%。备择假设和要检验的一致即接入率大于30%。\n然后我们要根据零假设得到一个总体中的占比值p，在这个假设下，看样本中150户中57户接入互联网的概率是多少？如果该概率小于5%，小于我们的显著性水平，那么我们就能拒绝零假设，接受备择假设。\n一开始假设零假设是正确的，根据该假设，我们得到总体均值$\\mu$或者说总体占比p，伯努利分布中$\\mu=p$。我要选择的这个占比值需要尽可能让得到这种情况的概率最大。得到样本中这种情况的概率现在还不知道。样本占比0.38，总体占比为0.3。\n根据伯努利分布，总体标准差$\\sigma_{H_0}=\\sqrt{(0.3)\\times(0.7)}=\\sqrt{0.21}$\n根据二项分布，np\u003e5，n(1-p)\u003e5\n样本占比分布的标准差$\\sigma_{\\bar P}=\\frac{\\sigma_{H_0}}{\\sqrt{150}}=0.037$\n$zscore=\\frac{\\bar P - \\mu_{\\bar P}}{\\sigma_{\\bar P}}=2.14$\n我们关心的单侧分布得到这个z统计量的概率是多于还是少于5%，如果少于5%，我们将拒绝零假设，接受备择假设。\n根据z-table，zscore对应的概率为0.9834，1-0.9834\u003c0.05，拒绝零假设，接受备择假设。\n54随机变量之差的方差 independent random variables X,Y\n$E(x)=\\mu_x$\n$Var(x)=E((X-\\mu_x)^2)=\\sigma_x^2$ X的方差等于X离其均值距离平方的期望值\nZ=X+Y==\u003eE(Z)=E(X)+E(Y)\nVar(Z)=Var(X)+Var(Y)\nZ=X-Y==\u003eE(Z)=E(X)-E(Y)\nVar(Z)=Var(X)+Var(-Y)=Var(X)+Var(Y)\n$E(a \\times X+b)=aE(X)+b$\n$D(a \\times X+b)=a^2D(X)$\n两个独立随机变量之差的方差等于两个方差之和\n55样本均值之差的分布 Z=X-Y==\u003eE(Z)=E(X)-E(Y)\nVar(Z)=Var(X)+Var(-Y)=Var(X)+Var(Y)\n样本均值抽样分布的方差$\\sigma_{\\bar x}^2=\\frac{\\sigma_x^2}{n}$\n$\\sigma_x^2$为实际总体分布的方差，而不是样本均值抽样分布的方差\n$\\sigma_{\\bar y}^2=\\frac{\\sigma_y^2}{m}$\n$\\sigma_{\\bar x- \\bar y}^2=\\sigma_{\\bar x}^2+\\sigma_{\\bar y}^2=\\frac{\\sigma_x^2}{n}+\\frac{\\sigma_y^2}{m}$\n56均值之差的置信区间 例：We’re trying to test whether a new, low-fat diet actually helps obese people lose weight. 100 randomly assigned obese people are assigned to group 1 and put on the low fat diet. Another 100 randomly assigned obese people assigned to group 2 and put on a diet of approximately the same amount of food, but not as low in fat. After 4 months, the mean weight loss was 9.31 lbs. for group 1 (s=4.67) and 7.40 lbs.(s=4.04) for group 2.\nlow -fat group : ${\\bar X_1}=9.31,s_1=4.67$\ncontrol group: ${\\bar X_2}=7.40, s_2=4.04$\n${\\bar X_1}-{\\bar X_2}=1.91$\n$\\sigma_{\\bar x- \\bar y}=\\sqrt{\\sigma_{\\bar x}^2+\\sigma_{\\bar y}^2}=\\sqrt{\\frac{\\sigma_x^2}{n}+\\frac{\\sigma_y^2}{m}}=\\sqrt{\\frac{s_1^2}{100}+\\frac{s_2^2}{100}}=0.617$\n95%置信区间\nz-score对应的概率为97.5%\n查阅z-table得到临界z值为1.96\n有95%几率分布的实际均值落在1.91左右1.96个标准差内即置信区间为0.70~3.12\n这里并非真正有95%几率实际均值的实际差值落在这个范围内，我们只是相信有95%的几率样本均值之差的实际期望值（实际均值的实际差值）落在0.7到3.12范围内，因为总体标准差或方差并非已知值。\n这个置信区间其实也是总体期望值之差的置信区间。如果给所有可能的人第一种节食方式，给所有可能的人第二种节食方式，这将给出总体均值之差的置信区间。根据这个结果，也许第一种节食方式是有效的，因为即使是置信区间的下限处仍然比第二种节食方式减轻更多体重。\n57均值之差的置信区间的澄清 $\\mu_{\\bar X - \\bar Y}=\\mu_{\\bar X_1}-\\mu_{\\bar X_2}=\\mu_1-\\mu_2$\n$\\mu_1-\\mu_2$是低脂节食同非低脂节食减肥效果的真实差异值，95%置信区间中，低脂节食方式更具减肥效果。\n58均值之差的假设检验 零假设：减肥效果无差异即$\\mu_1-\\mu_2=0$\n备择假设：（单侧）第一种节食方式减肥效果更好即$\\mu_1-\\mu_2\u003e0$\n5%显著性水平是说拒绝正确零假设的几率只有5%，也就是犯第一型错误的概率是5%。如果得到的概率小于5%，我们就拒绝原假设。\n首先假设有一个标准化正态分布，这样才能求出临界z值，\n根据z-table，95%对应的z值是1.65\n$\\sigma_{\\bar x- \\bar y}=\\sqrt{\\sigma_{\\bar x}^2+\\sigma_{\\bar y}^2}=\\sqrt{\\frac{\\sigma_x^2}{n}+\\frac{\\sigma_y^2}{m}}=\\sqrt{\\frac{s_1^2}{100}+\\frac{s_2^2}{100}}=0.617$\n如果第一种节食方式没效果的话，两个样本均值之差超过1.02的概率只有5%，但实际我们得到的均值的差值是1.91，这显然落在临界值之外，零假设前提下，得到这个的概率小于5%，得到这个差值的概率比显著性水平要低，我们拒绝零假设，接受备择假设即低脂节食方式确实能帮助减去更多体重。\n59总体占比的比较1 讨论男女投票情况是否有差异。找一个$\\bar P_1-\\bar P_2$ 的95%置信区间\n1000men 642 -1 rest -0 $\\bar P_1=0.642$\nsampling distribution of $\\bar P_1$\n$\\sigma_{\\bar P_1}^2=\\frac{\\sigma_{P_1^2}}{n}=\\frac{P_1(1-P_1)}{1000}$\n1000 women 591 -1 rest -0 $\\bar P_2=0.591$\nsampling distribution of $\\bar P_2$\n$\\sigma_{\\bar P_2}^2=\\frac{\\sigma_{P_2^2}}{n}=\\frac{P_2(1-P_2)}{1000}$\n$\\sigma_{\\bar P_1- \\bar P_2}=\\sqrt{\\frac{P_1(1-P_1)}{1000}+\\frac{P_2(1-P_2)}{1000}}=0.022$\n60总体占比的比较2 $\\bar P_1- \\bar P_2=0.051$\nconf: 95% chance that $\\bar P_1- \\bar P_2$ is within d(distance) of 0.051 也即 95%几率 0.051在均值$\\bar P_1- \\bar P_2$周围d之内\n95%的几率对应表中的97.5%，对应的zscore是1.96\n$d=1.96\\sigma_{\\bar P_1- \\bar P_2}=0.043$\n有95%的几率总体占比之差在样本占比之差左右0.043范围内\n投给某一特定候选人的男女总体占比之差的95%置信区间为[0.008, 0.094]\n该范围男性比女性占比更大\n61总体占比比较的假设检验 检验投给某个候选人的男性占比同女性占比之间是否有显著不同\n零假设是不存在差异，即$P_1- P_2=0$，P=0.6165\n显著性水平定为5%，双侧检验，均值左侧和均值右侧很远处的极端情况，都将让我们拒绝零假设。zscore对应的累积概率是97.5%。\n备择假设是存在差异。\n$\\sigma_{\\bar P_1- \\bar P_2}=\\sqrt{\\frac{2P(1-P)}{1000}}=0.0217$\n$zscore=\\frac{\\bar P_1-\\bar P_2-(P_1-P_2)}{\\sigma_{\\bar P_1- \\bar P_2}}=2.34$\n只有5%几率，零假设前提下，从z统计量中抽取的样本值大于1.96。\n拒绝零假设，选择备择假设。\n62线性回归中的平方误差 $y=mx+b$\n$SE_{line}=(y_1-mx_1-b)^2+…+(y_n-mx_n-b)^2$\n找m, b使得平方误差和SE最小\n63线性回归公式的推导1 对上面的公式进行展开 $SE_{line}=(y_1^2+y_2^2+…+y_n^2)-2m(x_1y_1+x_2y_2+…+x_ny_n)-2b(y_1+y_2+…+y_n)+m^2(x_1^2+x_2^2+…+x_n^2+2mb(x_1+x_2+…+x_n)+nb^2$\n64线性回归公式的推导2 n个点同直线之间平方误差之和\n$SE_{line}=n{\\bar {y^2}}-2mn\\bar {xy}-2bn \\bar y+m^2n{\\bar {x^2}}+2mbn\\bar x+nb^2$\n65线性回归公式的推导3 最小化需要对m,b分别求偏导然后令两个式子等于0计算出对应的m,b\n最小值点位于对m和b的斜率都为0的位置\n$\\frac{\\partial SE_{line}}{m}=-2n\\bar {xy}+2nm{\\bar {x^2}}+2bn{\\bar {x}}=0$\n$\\frac{\\partial SE_{line}}{b}=-2n{\\bar {y}}+2mn{\\bar {x}}+2bn=0$\n推导出$m{\\bar {x}}+b={\\bar {y}}$\n$m\\frac{{\\bar {x^2}}}{{\\bar {x}}}+b=\\frac{{\\bar {xy}}}{\\bar {x}}$\n可以发现两点都在直线上\n66线性回归公式的推导4 上面得到的结果消元求解\n$m=\\frac{{\\bar {x}{\\bar {y}}-{\\bar {xy}}}}{({\\bar {x}})^2-{\\bar {x^2}}}$\n$b={\\bar {y}}-m{\\bar {x}}$\n67线性回归例题 3个点（1，2）、（2，1），（4，3）\n$m=\\frac{7}{3}$\n$b=1$\n68决定系数R2 total variation in y: $SE_y = (y_1-\\bar y)^2+(y_2-\\bar y)^2+…+(y_n-\\bar y)^2$\n没被描述的波动$SE_{line}$，这个值越小，说明拟合效果越好\n总波动种被直线描述的百分比即决定系数coefficient of determination，记作R2=$1-\\frac{SE_{line}}{SE_{y}}$\n69线性回归例题2 70计算R2 71协方差和回归线 两个随机变量之间的协方差covariance定义：两个随机变量离各自均值距离之积的期望值\n$Cov(X,Y)=E[(X-E(X))(Y-E(Y))]=E(XY)-E[XE(Y)]-E(E(X)Y]+E[E(X)E(Y)]=E(XY)-E(X)E(Y)$\n协方差近似表示$Cov(XY)={\\bar {xy}}-{\\bar {x}}{\\bar {y}}$\n$Var(X)=Cov(X,X)={\\bar {x^2}}-({\\bar {x}})^2$\n$m=\\frac{Cov(X,Y)}{Var(X)}$\n72 $\\chi^2分布$ 卡方分布（英语：chi-square distribution, χ²-distribution，或写作χ²分布）是概率论与统计学中常用的一种概率分布。k个独立的标准正态分布变量的平方和服从自由度为k的卡方分布。卡方分布是一种特殊的伽玛分布，是统计推论中应用最为广泛的概率分布之一，例如假说检定和置信区间的计算。\n由卡方分布延伸出来皮尔森卡方检定常用于：\n1.样本某性质的比例分布与母体理论分布的拟合优度（例如某行政机关男女比是否符合该机关所在城镇的男女比）； 2.同一母体的两个随机变量是否独立（例如人的身高与交通违规的关联性）； 3.二或多个母体同一属性的同质性检定（义大利面店和寿司店的营业额有没有差距）。（详见皮尔森卡方检定） 概率密度函数\n累积分布函数\nχ^2（卡方）分布是一种概率分布，通常用于统计学中的假设检验和置信区间构建。它可以用于比较观察值和期望值之间的差异，如在卡方检验中使用。在实际应用中，χ^2分布通常用于分析分类数据的差异和相关性。\nχ^2分布的形状取决于自由度参数，自由度是一个与样本大小和数据维度有关的参数。当自由度越大时，χ^2分布趋向于正态分布，并且具有更小的方差。χ^2分布的平均值等于自由度，方差等于两倍自由度。\n在假设检验中，可以将观察值与期望值之间的差异表示为χ^2统计量，然后将该统计量与χ^2分布进行比较，以判断观察值是否符合期望值。如果χ^2统计量的值很大，那么观察值与期望值之间的差异就很大，表明可能存在某种关系或者模型不适合该数据。\n当我们想要测试一个硬币是否是公平的时候，我们可以进行一项硬币投掷实验。我们将硬币投掷n次，然后记录正面朝上的次数x。如果硬币是公平的，则我们期望正面朝上的次数为n/2。我们可以使用χ^2分布来判断观察值x是否符合期望值n/2。\n具体地，我们可以计算出χ^2统计量：\nχ^2 = Σ (observed - expected)^2 / expected\n其中，observed是观察到的正面朝上的次数，expected是期望正面朝上的次数，即n/2。\n假设我们将硬币投掷了10次，观察到正面朝上的次数为4。此时，期望正面朝上的次数为10/2=5。我们可以计算出χ^2统计量：\nχ^2 = (4-5)^2/5 + (6-5)^2/5 = 0.2\n接下来，我们可以使用χ^2分布表或者软件来查找自由度为1的χ^2分布，自由度为1表示我们只有一个自由度参数，即n-1=10-1=9。根据分布表或者软件，我们可以得到χ^2分布在自由度为1时的临界值为3.84。因为计算出的χ^2统计量0.2小于临界值3.84，所以我们不能拒绝原假设，即该硬币是公平的。\n这个例子说明了如何使用χ^2分布来进行假设检验。如果χ^2统计量大于临界值，则我们可以拒绝原假设，即观察值不符合期望值，可能存在某种关系或者模型不适合该数据。\n卡方分布表\np-value = 1- p_CDF.\nχ2越大，p-value越小，则可信度越高。通常用p=0.05作为阈值，即95%的可信度。\n常用的χ2与p-value表如下:\n自由度k \\ P value （概率） 0.95 0.90 0.80 0.70 0.50 0.30 0.20 0.10 0.05 0.01 0.001 1 0.004 0.02 0.06 0.15 0.46 1.07 1.64 2.71 3.84 6.64 10.83 2 0.10 0.21 0.45 0.71 1.39 2.41 3.22 4.60 5.99 9.21 13.82 3 0.35 0.58 1.01 1.42 2.37 3.66 4.64 6.25 7.82 11.34 16.27 4 0.71 1.06 1.65 2.20 3.36 4.88 5.99 7.78 9.49 13.28 18.47 5 1.14 1.61 2.34 3.00 4.35 6.06 7.29 9.24 11.07 15.09 20.52 6 1.63 2.20 3.07 3.83 5.35 7.23 8.56 10.64 12.59 16.81 22.46 7 2.17 2.83 3.82 4.67 6.35 8.38 9.80 12.02 14.07 18.48 24.32 8 2.73 3.49 4.59 5.53 7.34 9.52 11.03 13.36 15.51 20.09 26.12 9 3.32 4.17 5.38 6.39 8.34 10.66 12.24 14.68 16.92 21.67 27.88 10 3.94 4.86 6.18 7.27 9.34 11.78 13.44 15.99 18.31 23.21 29.59 73 皮尔逊$\\chi^2$检验 例题：检验给出的分布和观测的数据是否吻合\nDay M T W W F S Expected% 10 10 15 20 30 15 Observed 30 14 34 45 57 20 H0：给出的分布正确\nH1：给出的分布不正确\n显著性水平定为5%，如果$\\chi ^2$统计量得到如此极端甚至更极端的概率大于显著性水平则接受H0\n观测到的人数总和为200，根据分布，得到下面的期望值\nDay M T W W F S Expected% 10 10 15 20 30 15 Observed 30 14 34 45 57 20 Expected 20 20 30 40 60 30 具体地，我们可以计算出χ^2统计量：\nχ^2 = Σ (observed - expected)^2 / expected=11.44\n自由度=6-1=5（知道5条就能得知第6条）\n临界$\\chi^2$统计量为11.07\u003c11.44\n拒绝原假设H0\n显著性水平（significance level）是用于衡量统计推断中错误地拒绝原假设的概率。通常情况下，显著性水平被预先设定为一个小于1的数值，通常是0.05或0.01。这个数值表示如果原假设是真的，我们错误地拒绝原假设的概率，也就是犯第一类错误的概率。\n但是，显著性水平并不能代表原假设的正确率。原假设的正确率是指原假设为真时，我们正确地接受原假设的概率。这个概率通常称为“功效”（power），并且取决于多种因素，包括样本大小、效应大小、显著性水平和统计方法等。\n因此，在进行统计推断时，我们需要同时考虑显著性水平和功效，以便全面评估统计推断结果的可靠性和准确性。我们希望显著性水平尽可能小，以减少犯第一类错误的概率，但同时也需要考虑功效，以确保我们可以检测到真实的效应。\n74 列联表$\\chi^2$检验 contingency table列联表\n\\ Herb1 Herb2 Placebo安慰剂 患病或不患病的总人数 sick 30 30 30 80（21%） not sick 100 110 90 300（79%） 服用各种类型物品的总人数 120 140 120 380 预计患病人数 25.3 29.4 25.3 预计没患病人数 94.7 110.6 94.7 H0：草药无效果\nH1：有效果\n显著性水平10%\n$\\chi^2=\\frac{(20-25.3)^2}{25.3}+\\frac{(30-29.4)^2}{29.4}+\\frac{(20-25.3)^2}{25.3}+\\frac{(100-94.7)^2}{94.7}+\\frac{(110-110.6)^2}{110.6}+\\frac{(100-94.7)^2}{94.7}=2.53$\n列联表自由度=（行数-1）（列数-1）\n本题自由度为2\n4.60\u003e2.53\n根据现有数据，我们接受原假设。我们不能确定药草是否无效，但我们也不能说药草有效，我们无法拒绝原假设。虽然这不是100%正确，但我们无法拒绝它。\n75方差分析1：计算总平方和 C1 C2 C3 3 5 5 2 3 6 1 4 7 总平均值为4\n总平方和$SST=(3-4)^2+(2-4)^2+(1-4)^2+(5-4)^2+(5-4)^2+(4-4)^2+(5-4)^2+(6-4)^2+(7-4)^2=30$ 自由度是数据数-1，因为知道了总均值，最后一个值可以计算出来。\n这里自由度为$3\\times3-1=9-1=8$\n76方差分析2：组内和组间平方和 $\\bar x_1=2,\\bar x_2=4,\\bar x_3=6$\n组内平方和SSW：各点同各自组均值的距离平方之和\n$SSW=(3-2)^2+(2-2)^2+(1-2)^2+(5-4)^2+(5-4)^2+(4-4)^2+(5-6)^2+(6-6)^2+(7-6)^2=6$\n每组已知均值，每组n个数据，自由度为n-1\n这里自由度$3\\times(3-1)=6$\n总波动中有这么多来自组内波动。\n组间平方和SSB：来自均值之间的波动\n$SSB=3\\times(2-4)^2+3\\times(4-4)^2+3\\times(6-4)^2=24$\n一般而言，如果有m组，m个均值，自由度为m-1。\n这里自由度为3-1=2\n$SST=SSW+SSB$\n总自由度=m-1+m(n-1)=mn-1\n77方差分析3：F统计量假设检验 F检定 (F-test)，亦称联合假设检定（joint hypotheses test）、变异数比率检验、方差齐性检验。它是一种在零假设（null hypothesis, H0）之下，统计值服从F-分布的检验。其通常是用来分析用了超过一个参数的统计模型，以判断该模型中的全部或一部分参数是否适合用来估计母体。\nF检验这名称是由美国数学家兼统计学家George W. Snedecor命名，为了纪念英国统计学家兼生物学家罗纳德·费雪（Ronald Aylmer Fisher）。Fisher在1920年代发明了这个检验和F-分布，最初称为变异数比率（Variance Ratio）。\n适用场合\n检定一系列服从正态分布的母体是否有相同的标准差，此为最典型的F检定，此检定亦应用于变异数分析（ANOVA）中。\n回归分析\n检定整条回归模型是否具有解释力，此即Overall F检定 (Overall F test) 。 检定回归模型中特定自变数是否具有解释力，即偏回归系数是否为零，此即偏F检定（Partial F test)。 注意事项\nF检验对于数据的正态性非常敏感，因此在进行变异数同质性（homoscedasticity）检定时，Levene检验, Bartlett检验或者Brown–Forsythe检验的稳健性都要优于F检验。 F检验还可以用于三组或者多组之间的均值比较，但是如果被检验的数据无法满足均是正态分布的条件时，该数据的稳健型会大打折扣，特别是当显著性水平比较低时。但是，如果数据符合正态分布，而且alpha值至少为0.05，该检验的稳健型还是相当可靠的。\n若两个母体有相同的方差（方差齐性），那么可以采用F检验，但是该检验会呈现极端的非稳健性和非常态性，可以用t检验、巴特勒特检验等取代。\n与其它统计值的关系\nF检验的分子、分母其实各是一个卡方变数除以各自的自由度。 F检定用以检定单一变数可否排除于模型外时，即进行只缩减单一变数之偏F检定（Partial F test）时，$F=t^{2}$。 可参见 线性回归偏回归系数β的t检验。 这里存在一个无法衡量的总体均值，我们想知道是否有总体均值1=总体均值2=总体均值3？\nH0：三组食物影响无差异\nH1：有差异\n显著性水平定为10%，临界F值是3.46（右尾检验，分子自由度为2，分母自由度为6）\nAssume H0:\n$F-statistic=\\frac{\\frac{SSB}{m-1}}{\\frac{SSW}{m(n-1)}}$即组间平方和除以其自由度然后除以组内平方和除以其自由度\n本题中F统计量为12\nF分布其实是两个$\\chi^2$分布之比\n**F Distribution Tables** The F distribution is a right-skewed distribution used most commonly in Analysis of Variance. When referencing the F distribution, the numerator degrees of freedom are always given first, as switching the order of degrees of freedom changes the distribution (e.g., F(10,12) does not equal F(12,10) ). For the four F tables below, the rows represent denominator degrees of freedom and the columns represent numerator degrees of freedom. The right tail area is given in the name of the table. For example, to determine the .05 critical value for an F distribution with 10 and 12 degrees of freedom, look in the 10 column (numerator) and 12 row (denominator) of the F Table for alpha=.05. F(.05, 10, 12) = 2.7534. You can use the interactive F-Distribution Applet to obtain more accurate measures.\nF Table for α = 0.10\n\\|分子df1=1 2 3 4 5 6 7 8 9 10 12 15 20 24 30 40 60 120 ∞ 分母df2=1 39.86346 49.50000 53.59324 55.83296 57.24008 58.20442 58.90595 59.43898 59.85759 60.19498 60.70521 61.22034 61.74029 62.00205 62.26497 62.52905 62.79428 63.06064 63.32812 2 8.52632 9.00000 9.16179 9.24342 9.29263 9.32553 9.34908 9.36677 9.38054 9.39157 9.40813 9.42471 9.44131 9.44962 9.45793 9.46624 9.47456 9.48289 9.49122 3 5.53832 5.46238 5.39077 5.34264 5.30916 5.28473 5.26619 5.25167 5.24000 5.23041 5.21562 5.20031 5.18448 5.17636 5.16811 5.15972 5.15119 5.14251 5.13370 4 4.54477 4.32456 4.19086 4.10725 4.05058 4.00975 3.97897 3.95494 3.93567 3.91988 3.89553 3.87036 3.84434 3.83099 3.81742 3.80361 3.78957 3.77527 3.76073 5 4.06042 3.77972 3.61948 3.52020 3.45298 3.40451 3.36790 3.33928 3.31628 3.29740 3.26824 3.23801 3.20665 3.19052 3.17408 3.15732 3.14023 3.12279 3.10500 6 3.77595 3.46330 3.28876 3.18076 3.10751 3.05455 3.01446 2.98304 2.95774 2.93693 2.90472 2.87122 2.83634 2.81834 2.79996 2.78117 2.76195 2.74229 2.72216 7 3.58943 3.25744 3.07407 2.96053 2.88334 2.82739 2.78493 2.75158 2.72468 2.70251 2.66811 2.63223 2.59473 2.57533 2.55546 2.53510 2.51422 2.49279 2.47079 8 3.45792 3.11312 2.92380 2.80643 2.72645 2.66833 2.62413 2.58935 2.56124 2.53804 2.50196 2.46422 2.42464 2.40410 2.38302 2.36136 2.33910 2.31618 2.29257 9 3.36030 3.00645 2.81286 2.69268 2.61061 2.55086 2.50531 2.46941 2.44034 2.41632 2.37888 2.33962 2.29832 2.27683 2.25472 2.23196 2.20849 2.18427 2.15923 10 3.28502 2.92447 2.72767 2.60534 2.52164 2.46058 2.41397 2.37715 2.34731 2.32260 2.28405 2.24351 2.20074 2.17843 2.15543 2.13169 2.10716 2.08176 2.05542 11 3.22520 2.85951 2.66023 2.53619 2.45118 2.38907 2.34157 2.30400 2.27350 2.24823 2.20873 2.16709 2.12305 2.10001 2.07621 2.05161 2.02612 1.99965 1.97211 12 3.17655 2.80680 2.60552 2.48010 2.39402 2.33102 2.28278 2.24457 2.21352 2.18776 2.14744 2.10485 2.05968 2.03599 2.01149 1.98610 1.95973 1.93228 1.90361 13 3.13621 2.76317 2.56027 2.43371 2.34672 2.28298 2.23410 2.19535 2.16382 2.13763 2.09659 2.05316 2.00698 1.98272 1.95757 1.93147 1.90429 1.87591 1.84620 14 3.10221 2.72647 2.52222 2.39469 2.30694 2.24256 2.19313 2.15390 2.12195 2.09540 2.05371 2.00953 1.96245 1.93766 1.91193 1.88516 1.85723 1.82800 1.79728 15 3.07319 2.69517 2.48979 2.36143 2.27302 2.20808 2.15818 2.11853 2.08621 2.05932 2.01707 1.97222 1.92431 1.89904 1.87277 1.84539 1.81676 1.78672 1.75505 16 3.04811 2.66817 2.46181 2.33274 2.24376 2.17833 2.12800 2.08798 2.05533 2.02815 1.98539 1.93992 1.89127 1.86556 1.83879 1.81084 1.78156 1.75075 1.71817 17 3.02623 2.64464 2.43743 2.30775 2.21825 2.15239 2.10169 2.06134 2.02839 2.00094 1.95772 1.91169 1.86236 1.83624 1.80901 1.78053 1.75063 1.71909 1.68564 18 3.00698 2.62395 2.41601 2.28577 2.19583 2.12958 2.07854 2.03789 2.00467 1.97698 1.93334 1.88681 1.83685 1.81035 1.78269 1.75371 1.72322 1.69099 1.65671 19 2.98990 2.60561 2.39702 2.26630 2.17596 2.10936 2.05802 2.01710 1.98364 1.95573 1.91170 1.86471 1.81416 1.78731 1.75924 1.72979 1.69876 1.66587 1.63077 20 2.97465 2.58925 2.38009 2.24893 2.15823 2.09132 2.03970 1.99853 1.96485 1.93674 1.89236 1.84494 1.79384 1.76667 1.73822 1.70833 1.67678 1.64326 1.60738 21 2.96096 2.57457 2.36489 2.23334 2.14231 2.07512 2.02325 1.98186 1.94797 1.91967 1.87497 1.82715 1.77555 1.74807 1.71927 1.68896 1.65691 1.62278 1.58615 22 2.94858 2.56131 2.35117 2.21927 2.12794 2.06050 2.00840 1.96680 1.93273 1.90425 1.85925 1.81106 1.75899 1.73122 1.70208 1.67138 1.63885 1.60415 1.56678 23 2.93736 2.54929 2.33873 2.20651 2.11491 2.04723 1.99492 1.95312 1.91888 1.89025 1.84497 1.79643 1.74392 1.71588 1.68643 1.65535 1.62237 1.58711 1.54903 24 2.92712 2.53833 2.32739 2.19488 2.10303 2.03513 1.98263 1.94066 1.90625 1.87748 1.83194 1.78308 1.73015 1.70185 1.67210 1.64067 1.60726 1.57146 1.53270 25 2.91774 2.52831 2.31702 2.18424 2.09216 2.02406 1.97138 1.92925 1.89469 1.86578 1.82000 1.77083 1.71752 1.68898 1.65895 1.62718 1.59335 1.55703 1.51760 26 2.90913 2.51910 2.30749 2.17447 2.08218 2.01389 1.96104 1.91876 1.88407 1.85503 1.80902 1.75957 1.70589 1.67712 1.64682 1.61472 1.58050 1.54368 1.50360 27 2.90119 2.51061 2.29871 2.16546 2.07298 2.00452 1.95151 1.90909 1.87427 1.84511 1.79889 1.74917 1.69514 1.66616 1.63560 1.60320 1.56859 1.53129 1.49057 28 2.89385 2.50276 2.29060 2.15714 2.06447 1.99585 1.94270 1.90014 1.86520 1.83593 1.78951 1.73954 1.68519 1.65600 1.62519 1.59250 1.55753 1.51976 1.47841 29 2.88703 2.49548 2.28307 2.14941 2.05658 1.98781 1.93452 1.89184 1.85679 1.82741 1.78081 1.73060 1.67593 1.64655 1.61551 1.58253 1.54721 1.50899 1.46704 30 2.88069 2.48872 2.27607 2.14223 2.04925 1.98033 1.92692 1.88412 1.84896 1.81949 1.77270 1.72227 1.66731 1.63774 1.60648 1.57323 1.53757 1.49891 1.45636 40 2.83535 2.44037 2.22609 2.09095 1.99682 1.92688 1.87252 1.82886 1.79290 1.76269 1.71456 1.66241 1.60515 1.57411 1.54108 1.50562 1.46716 1.42476 1.37691 60 2.79107 2.39325 2.17741 2.04099 1.94571 1.87472 1.81939 1.77483 1.73802 1.70701 1.65743 1.60337 1.54349 1.51072 1.47554 1.43734 1.39520 1.34757 1.29146 120 2.74781 2.34734 2.12999 1.99230 1.89587 1.82381 1.76748 1.72196 1.68425 1.65238 1.60120 1.54500 1.48207 1.44723 1.40938 1.36760 1.32034 1.26457 1.19256 ∞ 2.70554 2.30259 2.08380 1.94486 1.84727 1.77411 1.71672 1.67020 1.63152 1.59872 1.54578 1.48714 1.42060 1.38318 1.34187 1.29513 1.23995 1.16860 1.00000 F Table for α = 0.01\n\\|df1=1 2 3 4 5 6 7 8 9 10 12 15 20 24 30 40 60 120 ∞ df2=1 4052.181 4999.500 5403.352 5624.583 5763.650 5858.986 5928.356 5981.070 6022.473 6055.847 6106.321 6157.285 6208.730 6234.631 6260.649 6286.782 6313.030 6339.391 6365.864 2 98.503 99.000 99.166 99.249 99.299 99.333 99.356 99.374 99.388 99.399 99.416 99.433 99.449 99.458 99.466 99.474 99.482 99.491 99.499 3 34.116 30.817 29.457 28.710 28.237 27.911 27.672 27.489 27.345 27.229 27.052 26.872 26.690 26.598 26.505 26.411 26.316 26.221 26.125 4 21.198 18.000 16.694 15.977 15.522 15.207 14.976 14.799 14.659 14.546 14.374 14.198 14.020 13.929 13.838 13.745 13.652 13.558 13.463 5 16.258 13.274 12.060 11.392 10.967 10.672 10.456 10.289 10.158 10.051 9.888 9.722 9.553 9.466 9.379 9.291 9.202 9.112 9.020 6 13.745 10.925 9.780 9.148 8.746 8.466 8.260 8.102 7.976 7.874 7.718 7.559 7.396 7.313 7.229 7.143 7.057 6.969 6.880 7 12.246 9.547 8.451 7.847 7.460 7.191 6.993 6.840 6.719 6.620 6.469 6.314 6.155 6.074 5.992 5.908 5.824 5.737 5.650 零假设前提下，得到如此极短的值得概率非常低，这个12比10%显著性水平的临界F统计量大太多。因此，我们拒绝原假设。\n附录如何使用临界 f 值计算器？ 计算器\n首先,这里有一些关于 F 分布概率的临界值 ：临界值是特定分布尾部的点,因此这些点到尾部的曲线下面积等于 α 的给定值。因此,对于双尾情况,临界值分别对应左右尾部的两个点,其性质为左尾部曲线下面积（从左临界点算起）与面积之和右尾曲线下等于给定的显着性水平 α。\n在左尾情况下,临界值对应于分布左尾的点,其特性是左尾曲线下的面积（从临界点到左边）等于给定的显着性水平 α。\n对于右尾情况,临界值对应于分布右尾的点,右尾曲线下的面积（从临界点向右）等于给定的显着性水平 α\n我们有一系列临界值计算器,包括 临界 z 值 , 临界的 t值 ,仅举几例。\n78相关性和因果性 correlation相关性：A和B有可能被同时观测到或者说B发生时A有可能同时发生\ncausality因果性：A导致B\n79演绎推理deductive reasoning 1 演绎推理：寻找规律或趋势，然后推广。\n三段式演绎推理\n比如预测小镇人数。\n演绎推理（Deductive Reasoning）\n演绎推理来自于逻辑学，它是通过一般的原理或规则来推导出特定的结论。如果前提是真的，那么演绎推理的结论就必须是真的。例如，如果所有人都是有死亡的（前提），那么我也会死亡（结论）。这就是一个演绎推理的例子。在演绎推理中，前提的真实性决定了结论的真实性。\n归纳推理（Inductive Reasoning）\n归纳推理是从特定的实例或例子中发现一般性的规律或原理。归纳推理的结果往往是可能性的，而不是必然性的。例如，如果我看到太阳每天都从东边升起（观察的实例），我可能会推理出太阳每天都会从东边升起（一般规律）。但是，这个结论并不是必然正确的，因为这只是基于我有限的观察得出的。\n演绎推理与归纳推理的异同\n相同点：两者都是推理的方式，都是通过某种思考过程从一种信息（前提或观察）得出结论。\n不同点：演绎推理从一般到特殊，若前提真实，那么结论必然真实；归纳推理从特殊到一般，结论只是可能真实，并非必然真实。另外，演绎推理通常用在数学或逻辑学中，而归纳推理则更常用在科学研究中。\n80演绎推理2 解方程，从事实出发，使用逻辑步骤运算或推理，得到其它事实，这里没有推广\n81演绎推理3 推导$(x+y)^=x^2+2xy+y^2$\n从一个式子出发，使用逻辑步骤运算或推理，得到其它事实\n演绎推理是从前提中推导出结论的推理方法。以下是一些演绎推理的例子：\n如果所有的狗都会叫，而且这只动物是一只狗，那么它一定会叫。\n如果所有的人类都需要呼吸氧气，而且这个人是一个人类，那么他一定需要呼吸氧气。\n如果所有蒸汽都会形成云，而且这些白色的云是蒸汽形成的，那么它们一定是蒸汽。\n如果所有的矿泉水都含有矿物质，而且这瓶水是矿泉水，那么它一定含有矿物质。\n如果所有的植物都需要阳光和水才能生长，而且这颗植物缺乏阳光，那么它无法正常生长。\n这些例子展示了演绎推理方法的应用，即从已知的前提中推导出结论。演绎推理可以保证结论的准确性，只要前提是真实的，结论就是正确的。在科学、数学、逻辑等领域中，演绎推理是非常重要的，因为它可以帮助我们得出精确的结论和定理。\n82归纳推理inductive reasoning1 找共性\n如6, 9, 12, 15……\n83归纳推理2 如0, 3, 8, 15, 24,……\n找规律推测第n个数是$n^2-1$\n首先根据已知数据了解规律，然后推广规律，但这结果不一定正确\n84归纳推理3 归纳推理是通过具体的实例来推断出一般规律或结论的推理方法。以下是一些归纳推理的例子：\n假设你已经观察到很多鸟都有羽毛，并且你还没有遇到过没有羽毛的鸟，因此你可以归纳出“所有鸟都有羽毛”这一结论。\n假设你已经试着用不同的铅笔在不同的纸上写字，你发现所有的铅笔都可以写字，因此你可以归纳出“所有铅笔都可以写字”这一结论。\n假设你已经观察到很多人都穿着厚外套在寒冷的天气中行走，并且你还没有遇到过不穿外套的人，因此你可以归纳出“在寒冷的天气中，人们通常穿着厚外套”这一结论。\n假设你已经试着用不同的电子设备播放音乐，你发现所有的设备都可以播放音乐，因此你可以归纳出“所有电子设备都可以播放音乐”这一结论。\n这些例子说明了归纳推理方法的应用，即通过观察和实验来推断出一般规律或结论。虽然归纳推理不能保证结论的绝对准确性，但在日常生活中，它可以为我们提供很多有用的信息和指导。\n85 归纳规律 ","wordCount":"22045","inLanguage":"zh","datePublished":"2023-07-27T11:34:25+08:00","dateModified":"2025-10-20T21:28:22+08:00","author":{"@type":"Person","name":"RM"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://rosefinch-midsummer.github.io/zh/posts/course/khanacademy%E7%BB%9F%E8%AE%A1%E5%AD%A6/"},"publisher":{"@type":"Organization","name":"天漢帝國復興錄","logo":{"@type":"ImageObject","url":"https://rosefinch-midsummer.github.io/img/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://rosefinch-midsummer.github.io/zh/ accesskey=h title="天漢帝國復興錄 (Alt + H)">天漢帝國復興錄</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://rosefinch-midsummer.github.io/zh/ title=🏠主頁><span>🏠主頁</span></a></li><li><a href=https://rosefinch-midsummer.github.io/zh/posts title=📚文章><span>📚文章</span></a></li><li><a href=https://rosefinch-midsummer.github.io/zh/search title="🔍搜索 (Alt + /)" accesskey=/><span>🔍搜索</span></a></li><li><a href=https://rosefinch-midsummer.github.io/zh/archives title=⏱時間軸><span>⏱時間軸</span></a></li><li><a href=https://rosefinch-midsummer.github.io/zh/categories title=🧩分類><span>🧩分類</span></a></li><li><a href=https://rosefinch-midsummer.github.io/zh/tags title=🔖標簽><span>🔖標簽</span></a></li><li><a href=https://rosefinch-midsummer.github.io/zh/about title=🙋🏻‍♂️關于><span>🙋🏻‍♂️關于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://rosefinch-midsummer.github.io/zh/>首頁</a>&nbsp;»&nbsp;<a href=https://rosefinch-midsummer.github.io/zh/posts/>📚文章</a>&nbsp;»&nbsp;<a href=https://rosefinch-midsummer.github.io/zh/posts/course/>🏫課程</a></div><h1 class=post-title>KhanAcademy《统计学》</h1><div class=post-meta>创建: 2023-07-27 |
更新: 2025-10-20 |
字数: 22045字 |
时长: 45分钟 |
RM</div><div class=meta-item>&nbsp·&nbsp
<span id=busuanzi_container_page_pv>本文阅读量<span id=busuanzi_value_page_pv></span>次</span></div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>目錄</span></summary><div class=inner><ul><li><a href=#1%e5%9d%87%e5%80%bc%e4%b8%ad%e4%bd%8d%e6%95%b0%e4%bc%97%e6%95%b0 aria-label=1均值、中位数、众数>1均值、中位数、众数</a></li><li><a href=#2%e6%9e%81%e5%b7%ae%e4%b8%ad%e7%a8%8b%e6%95%b0 aria-label=2极差、中程数>2极差、中程数</a></li><li><a href=#3%e8%b1%a1%e5%bd%a2%e7%bb%9f%e8%ae%a1%e5%9b%be aria-label=3象形统计图>3象形统计图</a></li><li><a href=#4%e6%9d%a1%e5%bd%a2%e5%9b%be aria-label=4条形图>4条形图</a></li><li><a href=#5%e6%8a%98%e7%ba%bf%e5%9b%be aria-label=5折线图>5折线图</a></li><li><a href=#6%e9%a5%bc%e5%9b%be aria-label=6饼图>6饼图</a></li><li><a href=#7%e8%af%af%e5%af%bc%e4%ba%ba%e7%9a%84%e6%8a%98%e7%ba%bf%e5%9b%be aria-label=7误导人的折线图>7误导人的折线图</a></li><li><a href=#8%e8%8c%8e%e5%8f%b6%e5%9b%be aria-label=8茎叶图>8茎叶图</a></li><li><a href=#9%e7%ae%b1%e7%ba%bf%e5%9b%be aria-label=9箱线图>9箱线图</a></li><li><a href=#10%e7%ae%b1%e7%ba%bf%e5%9b%be2 aria-label=10箱线图2>10箱线图2</a></li><li><a href=#11%e7%bb%9f%e8%ae%a1%e9%9b%86%e4%b8%ad%e8%b6%8b%e5%8a%bf aria-label=11统计：集中趋势>11统计：集中趋势</a></li><li><a href=#12%e7%bb%9f%e8%ae%a1%e6%a0%b7%e6%9c%ac%e5%92%8c%e6%80%bb%e4%bd%93 aria-label=12统计：样本和总体>12统计：样本和总体</a></li><li><a href=#13%e7%bb%9f%e8%ae%a1%e6%80%bb%e4%bd%93%e6%96%b9%e5%b7%ae aria-label=13统计：总体方差>13统计：总体方差</a></li><li><a href=#14%e7%bb%9f%e8%ae%a1%e6%a0%b7%e6%9c%ac%e6%96%b9%e5%b7%ae aria-label=14统计：样本方差>14统计：样本方差</a></li><li><a href=#15%e7%bb%9f%e8%ae%a1%e6%a0%87%e5%87%86%e5%b7%ae aria-label=15统计：标准差>15统计：标准差</a></li><li><a href=#16%e7%bb%9f%e8%ae%a1%e8%af%b8%e6%96%b9%e5%b7%ae%e5%85%ac%e5%bc%8f aria-label=16统计：诸方差公式>16统计：诸方差公式</a></li><li><a href=#17%e9%9a%8f%e6%9c%ba%e5%8f%98%e9%87%8f%e4%bb%8b%e7%bb%8d aria-label=17随机变量介绍>17随机变量介绍</a></li><li><a href=#18%e6%a6%82%e7%8e%87%e5%af%86%e5%ba%a6%e5%87%bd%e6%95%b0 aria-label=18概率密度函数>18概率密度函数</a></li><li><a href=#19%e4%ba%8c%e9%a1%b9%e5%88%86%e5%b8%831 aria-label=19二项分布1>19二项分布1</a></li><li><a href=#20%e4%ba%8c%e9%a1%b9%e5%88%86%e5%b8%832 aria-label=20二项分布2>20二项分布2</a></li><li><a href=#21%e4%ba%8c%e9%a1%b9%e5%88%86%e5%b8%833 aria-label=21二项分布3>21二项分布3</a></li><li><a href=#22%e4%ba%8c%e9%a1%b9%e5%88%86%e5%b8%834 aria-label=22二项分布4>22二项分布4</a></li><li><a href=#23%e6%9c%9f%e6%9c%9b%e5%80%bcex aria-label=23期望值E(x)>23期望值E(x)</a></li><li><a href=#24%e4%ba%8c%e9%a1%b9%e5%88%86%e5%b8%83%e7%9a%84%e6%9c%9f%e6%9c%9b%e5%80%bc aria-label=24二项分布的期望值>24二项分布的期望值</a></li><li><a href=#25%e6%b3%8a%e6%9d%be%e8%bf%87%e7%a8%8b1 aria-label=25泊松过程1>25泊松过程1</a></li><li><a href=#26%e6%b3%8a%e6%9d%be%e8%bf%87%e7%a8%8b2 aria-label=26泊松过程2>26泊松过程2</a><ul><ul><li><a href=#%e6%b3%8a%e6%9d%be%e5%88%86%e5%b8%83%e6%b1%82%e6%9c%9f%e6%9c%9b aria-label=泊松分布求期望：>泊松分布求期望：</a></li><li><a href=#%e6%b3%8a%e6%9d%be%e5%88%86%e5%b8%83%e6%b1%82%e6%96%b9%e5%b7%ae aria-label=泊松分布求方差：>泊松分布求方差：</a></li><li><a href=#%e7%bb%84%e5%90%88%e6%b3%8a%e6%9d%be%e5%88%86%e5%b8%83 aria-label=组合泊松分布：>组合泊松分布：</a></li><li><a href=#%e6%ac%a1%e6%95%b0%e8%bf%87%e5%a4%9a%e7%9a%84%e4%ba%8c%e9%a1%b9%e5%88%86%e5%b8%83%e4%bd%bf%e7%94%a8%e6%b3%8a%e6%9d%be%e5%88%86%e5%b8%83%e6%b1%82%e8%a7%a3 aria-label=次数过多的二项分布使用泊松分布求解：>次数过多的二项分布使用泊松分布求解：</a></li></ul></ul></li><li><a href=#27%e5%a4%a7%e6%95%b0%e5%ae%9a%e5%be%8b aria-label=27大数定律>27大数定律</a></li><li><a href=#28%e6%ad%a3%e6%80%81%e5%88%86%e5%b8%83excel%e7%bb%83%e4%b9%a0 aria-label=28正态分布Excel练习>28正态分布Excel练习</a></li><li><a href=#29%e6%ad%a3%e6%80%81%e5%88%86%e5%b8%83%e4%bb%8b%e7%bb%8d aria-label=29正态分布介绍>29正态分布介绍</a></li><li><a href=#30%e6%ad%a3%e6%80%81%e5%88%86%e5%b8%83%e9%97%ae%e9%a2%98%e5%93%aa%e4%ba%9b%e6%98%af%e6%ad%a3%e6%80%81%e5%88%86%e5%b8%83 aria-label=30正态分布问题：哪些是正态分布？>30正态分布问题：哪些是正态分布？</a></li><li><a href=#31%e6%ad%a3%e6%80%81%e5%88%86%e5%b8%83%e9%97%ae%e9%a2%98z%e5%88%86%e6%95%b0 aria-label=31正态分布问题：z分数>31正态分布问题：z分数</a></li><li><a href=#32%e6%ad%a3%e6%80%81%e5%88%86%e5%b8%83%e9%97%ae%e9%a2%98%e7%bb%8f%e9%aa%8c%e6%b3%95%e5%88%99 aria-label=32正态分布问题：经验法则>32正态分布问题：经验法则</a></li><li><a href=#33%e7%bb%83%e4%b9%a0%e6%a0%87%e5%87%86%e6%ad%a3%e6%80%81%e5%88%86%e5%b8%83%e5%92%8c%e7%bb%8f%e9%aa%8c%e6%b3%95%e5%88%99 aria-label=33练习：标准正态分布和经验法则>33练习：标准正态分布和经验法则</a></li><li><a href=#34%e7%bb%8f%e9%aa%8c%e6%b3%95%e5%88%99%e5%92%8cz%e5%88%86%e6%95%b0%e7%9a%84%e8%bf%9b%e4%b8%80%e6%ad%a5%e7%bb%83%e4%b9%a0 aria-label=34经验法则和z分数的进一步练习>34经验法则和z分数的进一步练习</a></li><li><a href=#35%e4%b8%ad%e5%bf%83%e6%9e%81%e9%99%90%e5%ae%9a%e7%90%86 aria-label=35中心极限定理>35中心极限定理</a></li><li><a href=#36%e6%a0%b7%e6%9c%ac%e5%9d%87%e5%80%bc%e7%9a%84%e6%8a%bd%e6%a0%b7%e5%88%86%e5%b8%83 aria-label=36样本均值的抽样分布>36样本均值的抽样分布</a><ul><li><a href=#%e5%81%8f%e5%ba%a6 aria-label=偏度>偏度</a></li><li><a href=#%e5%b3%b0%e5%ba%a6 aria-label=峰度>峰度</a></li></ul></li><li><a href=#37%e6%a0%b7%e6%9c%ac%e5%9d%87%e5%80%bc%e7%9a%84%e6%8a%bd%e6%a0%b7%e5%88%86%e5%b8%832 aria-label=37样本均值的抽样分布2>37样本均值的抽样分布2</a></li><li><a href=#38%e5%9d%87%e5%80%bc%e6%a0%87%e5%87%86%e8%af%af%e5%b7%ae aria-label=38均值标准误差>38均值标准误差</a></li><li><a href=#39%e6%8a%bd%e6%a0%b7%e5%88%86%e5%b8%83%e4%be%8b%e9%a2%98 aria-label=39抽样分布例题>39抽样分布例题</a></li><li><a href=#40%e7%bd%ae%e4%bf%a1%e5%8c%ba%e9%97%b4 aria-label=40置信区间>40置信区间</a></li><li><a href=#41%e4%bc%af%e5%8a%aa%e5%88%a9%e5%88%86%e5%b8%83%e5%9d%87%e5%80%bc%e5%92%8c%e6%96%b9%e5%b7%ae%e7%9a%84%e4%be%8b%e5%ad%90 aria-label=41伯努利分布均值和方差的例子>41伯努利分布均值和方差的例子</a></li><li><a href=#42%e4%bc%af%e5%8a%aa%e5%88%a9%e5%88%86%e5%b8%83%e5%9d%87%e5%80%bc%e5%92%8c%e6%96%b9%e5%b7%ae%e7%9a%84%e5%85%ac%e5%bc%8f aria-label=42伯努利分布均值和方差的公式>42伯努利分布均值和方差的公式</a></li><li><a href=#43%e8%af%af%e5%b7%ae%e8%8c%83%e5%9b%b41 aria-label=43误差范围1>43误差范围1</a></li><li><a href=#44%e8%af%af%e5%b7%ae%e8%8c%83%e5%9b%b42 aria-label=44误差范围2>44误差范围2</a></li><li><a href=#45%e7%bd%ae%e4%bf%a1%e5%8c%ba%e9%97%b4%e4%be%8b%e9%a2%98 aria-label=45置信区间例题>45置信区间例题</a></li><li><a href=#46%e5%b0%8f%e6%a0%b7%e6%9c%ac%e5%ae%b9%e9%87%8f%e7%bd%ae%e4%bf%a1%e5%8c%ba%e9%97%b4 aria-label=46小样本容量置信区间>46小样本容量置信区间</a></li><li><a href=#47%e5%81%87%e8%ae%be%e6%a3%80%e9%aa%8c%e5%92%8cp%e5%80%bc aria-label=47假设检验和p值>47假设检验和p值</a></li><li><a href=#48%e5%8d%95%e4%be%a7%e6%a3%80%e9%aa%8c%e5%92%8c%e5%8f%8c%e4%be%a7%e6%a3%80%e9%aa%8c aria-label=48单侧检验和双侧检验>48单侧检验和双侧检验</a></li><li><a href=#49z%e7%bb%9f%e8%ae%a1%e9%87%8fvst%e7%bb%9f%e8%ae%a1%e9%87%8f aria-label=49z统计量VSt统计量>49z统计量VSt统计量</a></li><li><a href=#50-%e7%ac%ac%e4%b8%80%e5%9e%8b%e9%94%99%e8%af%af aria-label="50 第一型错误">50 第一型错误</a></li><li><a href=#51%e5%b0%8f%e6%a0%b7%e6%9c%ac%e5%81%87%e8%ae%be%e6%a3%80%e9%aa%8c aria-label=51小样本假设检验>51小样本假设检验</a></li><li><a href=#52t%e7%bb%9f%e8%ae%a1%e9%87%8f%e7%bd%ae%e4%bf%a1%e5%8c%ba%e9%97%b4 aria-label=52t统计量置信区间>52t统计量置信区间</a></li><li><a href=#53%e5%a4%a7%e6%a0%b7%e6%9c%ac%e5%8d%a0%e6%af%94%e5%81%87%e8%ae%be%e6%a3%80%e9%aa%8c aria-label=53大样本占比假设检验>53大样本占比假设检验</a></li><li><a href=#54%e9%9a%8f%e6%9c%ba%e5%8f%98%e9%87%8f%e4%b9%8b%e5%b7%ae%e7%9a%84%e6%96%b9%e5%b7%ae aria-label=54随机变量之差的方差>54随机变量之差的方差</a></li><li><a href=#55%e6%a0%b7%e6%9c%ac%e5%9d%87%e5%80%bc%e4%b9%8b%e5%b7%ae%e7%9a%84%e5%88%86%e5%b8%83 aria-label=55样本均值之差的分布>55样本均值之差的分布</a></li><li><a href=#56%e5%9d%87%e5%80%bc%e4%b9%8b%e5%b7%ae%e7%9a%84%e7%bd%ae%e4%bf%a1%e5%8c%ba%e9%97%b4 aria-label=56均值之差的置信区间>56均值之差的置信区间</a></li><li><a href=#57%e5%9d%87%e5%80%bc%e4%b9%8b%e5%b7%ae%e7%9a%84%e7%bd%ae%e4%bf%a1%e5%8c%ba%e9%97%b4%e7%9a%84%e6%be%84%e6%b8%85 aria-label=57均值之差的置信区间的澄清>57均值之差的置信区间的澄清</a></li><li><a href=#58%e5%9d%87%e5%80%bc%e4%b9%8b%e5%b7%ae%e7%9a%84%e5%81%87%e8%ae%be%e6%a3%80%e9%aa%8c aria-label=58均值之差的假设检验>58均值之差的假设检验</a></li><li><a href=#59%e6%80%bb%e4%bd%93%e5%8d%a0%e6%af%94%e7%9a%84%e6%af%94%e8%be%831 aria-label=59总体占比的比较1>59总体占比的比较1</a></li><li><a href=#60%e6%80%bb%e4%bd%93%e5%8d%a0%e6%af%94%e7%9a%84%e6%af%94%e8%be%832 aria-label=60总体占比的比较2>60总体占比的比较2</a></li><li><a href=#61%e6%80%bb%e4%bd%93%e5%8d%a0%e6%af%94%e6%af%94%e8%be%83%e7%9a%84%e5%81%87%e8%ae%be%e6%a3%80%e9%aa%8c aria-label=61总体占比比较的假设检验>61总体占比比较的假设检验</a></li><li><a href=#62%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e4%b8%ad%e7%9a%84%e5%b9%b3%e6%96%b9%e8%af%af%e5%b7%ae aria-label=62线性回归中的平方误差>62线性回归中的平方误差</a></li><li><a href=#63%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e5%85%ac%e5%bc%8f%e7%9a%84%e6%8e%a8%e5%af%bc1 aria-label=63线性回归公式的推导1>63线性回归公式的推导1</a></li><li><a href=#64%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e5%85%ac%e5%bc%8f%e7%9a%84%e6%8e%a8%e5%af%bc2 aria-label=64线性回归公式的推导2>64线性回归公式的推导2</a></li><li><a href=#65%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e5%85%ac%e5%bc%8f%e7%9a%84%e6%8e%a8%e5%af%bc3 aria-label=65线性回归公式的推导3>65线性回归公式的推导3</a></li><li><a href=#66%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e5%85%ac%e5%bc%8f%e7%9a%84%e6%8e%a8%e5%af%bc4 aria-label=66线性回归公式的推导4>66线性回归公式的推导4</a></li><li><a href=#67%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e4%be%8b%e9%a2%98 aria-label=67线性回归例题>67线性回归例题</a></li><li><a href=#68%e5%86%b3%e5%ae%9a%e7%b3%bb%e6%95%b0r2 aria-label=68决定系数R2>68决定系数R2</a></li><li><a href=#69%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e4%be%8b%e9%a2%982 aria-label=69线性回归例题2>69线性回归例题2</a></li><li><a href=#70%e8%ae%a1%e7%ae%97r2 aria-label=70计算R2>70计算R2</a></li><li><a href=#71%e5%8d%8f%e6%96%b9%e5%b7%ae%e5%92%8c%e5%9b%9e%e5%bd%92%e7%ba%bf aria-label=71协方差和回归线>71协方差和回归线</a></li><li><a href=#72-chi2%e5%88%86%e5%b8%83 aria-label="72 $\chi^2分布$">72 $\chi^2分布$</a></li><li><a href=#73-%e7%9a%ae%e5%b0%94%e9%80%8achi2%e6%a3%80%e9%aa%8c aria-label="73 皮尔逊$\chi^2$检验">73 皮尔逊$\chi^2$检验</a></li><li><a href=#74-%e5%88%97%e8%81%94%e8%a1%a8chi2%e6%a3%80%e9%aa%8c aria-label="74 列联表$\chi^2$检验">74 列联表$\chi^2$检验</a></li><li><a href=#75%e6%96%b9%e5%b7%ae%e5%88%86%e6%9e%901%e8%ae%a1%e7%ae%97%e6%80%bb%e5%b9%b3%e6%96%b9%e5%92%8c aria-label=75方差分析1：计算总平方和>75方差分析1：计算总平方和</a></li><li><a href=#76%e6%96%b9%e5%b7%ae%e5%88%86%e6%9e%902%e7%bb%84%e5%86%85%e5%92%8c%e7%bb%84%e9%97%b4%e5%b9%b3%e6%96%b9%e5%92%8c aria-label=76方差分析2：组内和组间平方和>76方差分析2：组内和组间平方和</a></li><li><a href=#77%e6%96%b9%e5%b7%ae%e5%88%86%e6%9e%903f%e7%bb%9f%e8%ae%a1%e9%87%8f%e5%81%87%e8%ae%be%e6%a3%80%e9%aa%8c aria-label=77方差分析3：F统计量假设检验>77方差分析3：F统计量假设检验</a></li><li><a href=#%e9%99%84%e5%bd%95%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8%e4%b8%b4%e7%95%8c-f-%e5%80%bc%e8%ae%a1%e7%ae%97%e5%99%a8 aria-label="附录如何使用临界 f 值计算器？">附录如何使用临界 f 值计算器？</a></li><li><a href=#78%e7%9b%b8%e5%85%b3%e6%80%a7%e5%92%8c%e5%9b%a0%e6%9e%9c%e6%80%a7 aria-label=78相关性和因果性>78相关性和因果性</a></li><li><a href=#79%e6%bc%94%e7%bb%8e%e6%8e%a8%e7%90%86deductive-reasoning-1 aria-label="79演绎推理deductive reasoning 1">79演绎推理deductive reasoning 1</a></li><li><a href=#80%e6%bc%94%e7%bb%8e%e6%8e%a8%e7%90%862 aria-label=80演绎推理2>80演绎推理2</a></li><li><a href=#81%e6%bc%94%e7%bb%8e%e6%8e%a8%e7%90%863 aria-label=81演绎推理3>81演绎推理3</a></li><li><a href=#82%e5%bd%92%e7%ba%b3%e6%8e%a8%e7%90%86inductive-reasoning1 aria-label="82归纳推理inductive reasoning1">82归纳推理inductive reasoning1</a></li><li><a href=#83%e5%bd%92%e7%ba%b3%e6%8e%a8%e7%90%862 aria-label=83归纳推理2>83归纳推理2</a></li><li><a href=#84%e5%bd%92%e7%ba%b3%e6%8e%a8%e7%90%863 aria-label=84归纳推理3>84归纳推理3</a></li><li><a href=#85-%e5%bd%92%e7%ba%b3%e8%a7%84%e5%be%8b aria-label="85 归纳规律">85 归纳规律</a></li></ul></div></details></div><div class=post-content><p><a href=https://mathcracker.com/zh/>在线计算器和解决数学问题</a></p><h2 id=1均值中位数众数>1均值、中位数、众数<a hidden class=anchor aria-hidden=true href=#1均值中位数众数>#</a></h2><p>均值mean、中位数median、众数mode</p><h2 id=2极差中程数>2极差、中程数<a hidden class=anchor aria-hidden=true href=#2极差中程数>#</a></h2><p>极差range、中程数mid-range</p><p>中程数是最大值和最小值的平均数。</p><h2 id=3象形统计图>3象形统计图<a hidden class=anchor aria-hidden=true href=#3象形统计图>#</a></h2><p>用符号表示数据类型，比如一滴血代表8个人，在统计图中画血的符号。</p><h2 id=4条形图>4条形图<a hidden class=anchor aria-hidden=true href=#4条形图>#</a></h2><p>bar graph</p><p>将事物进行分类，并看每一类分别的怎样的情况</p><h2 id=5折线图>5折线图<a hidden class=anchor aria-hidden=true href=#5折线图>#</a></h2><p>line graph</p><p>反映变化趋势</p><h2 id=6饼图>6饼图<a hidden class=anchor aria-hidden=true href=#6饼图>#</a></h2><p>pie graph</p><p>看各部分的占比</p><h2 id=7误导人的折线图>7误导人的折线图<a hidden class=anchor aria-hidden=true href=#7误导人的折线图>#</a></h2><h2 id=8茎叶图>8茎叶图<a hidden class=anchor aria-hidden=true href=#8茎叶图>#</a></h2><p>stem-and-leaf plot</p><h2 id=9箱线图>9箱线图<a hidden class=anchor aria-hidden=true href=#9箱线图>#</a></h2><p>box-and-whiskers plot</p><p>看数据的散布情况和中位数</p><p>先求中位数，然后以中位数为界求前后两段的中位数作为四分位数</p><h2 id=10箱线图2>10箱线图2<a hidden class=anchor aria-hidden=true href=#10箱线图2>#</a></h2><h2 id=11统计集中趋势>11统计：集中趋势<a hidden class=anchor aria-hidden=true href=#11统计集中趋势>#</a></h2><p>Statistics分为描述性统计学DescriptiveStatistics和推断统计学InferentialStatistics</p><p>Central Tendency通常用算数平均数、中位数、众数表示。</p><h2 id=12统计样本和总体>12统计：样本和总体<a hidden class=anchor aria-hidden=true href=#12统计样本和总体>#</a></h2><p>样本sample</p><p>总体population</p><p>样本均值$\bar x$</p><p>总体均值$\mu$</p><h2 id=13统计总体方差>13统计：总体方差<a hidden class=anchor aria-hidden=true href=#13统计总体方差>#</a></h2><p>离散程度dispersion</p><p>0 0 5 5和2 2 3 3的平均数相同</p><p>总体方差$\sigma^2=\frac{\sum_{i=1}^N(x_i-\mu)^2}{N}$</p><h2 id=14统计样本方差>14统计：样本方差<a hidden class=anchor aria-hidden=true href=#14统计样本方差>#</a></h2><p>样本方差$\sigma^2=\frac{\sum_{i=1}^n(x_i-\bar x)^2}{n}$</p><p>样本方差$\sigma^2=\frac{\sum_{i=1}^n(x_i-\bar x)^2}{n}\leq总体方差\sigma^2=\frac{\sum_{i=1}^n(x_i-\mu)^2}{n}$</p><p>总体方差的无偏估计（unbiased estimate of the population variance）或称之为无偏样本方差（unbiased sample variance）</p><p>方差$\sigma^2=\frac{\sum_{i=1}^n(x_i-\bar x)^2}{n-1}$</p><h2 id=15统计标准差>15统计：标准差<a hidden class=anchor aria-hidden=true href=#15统计标准差>#</a></h2><p>standard deviation标准差的单位更好</p><h2 id=16统计诸方差公式>16统计：诸方差公式<a hidden class=anchor aria-hidden=true href=#16统计诸方差公式>#</a></h2><p>总体方差$\sigma^2=\frac{\sum_{i=1}^N(x_i-\mu)^2}{N}$可化为$\sigma^2=\frac{\sum_{i=1}^Nx_i^2}{N}-\mu^2$</p><h2 id=17随机变量介绍>17随机变量介绍<a hidden class=anchor aria-hidden=true href=#17随机变量介绍>#</a></h2><p>random variable一般用大写字母表示，随机变量实际上是一种函数——将random process随机过程映射到实际数字的函数。如抛硬币过程：</p><p>$$X=
\begin{cases}
1,&amp;if hats\
0,&amp;if tails
\end{cases}
$$</p><p>随机变量分为连续型continuous随机变量和离散型discrete随机变量。</p><h2 id=18概率密度函数>18概率密度函数<a hidden class=anchor aria-hidden=true href=#18概率密度函数>#</a></h2><p>离散型随机变量有概率分布函数（probability distribution function）</p><p><img loading=lazy src=https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost01/img/20230713093939.png></p><p>连续型随机变量有概率密度函数（probability density function）</p><p><img loading=lazy src=https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost01/img/20230713094018.png></p><h2 id=19二项分布1>19二项分布1<a hidden class=anchor aria-hidden=true href=#19二项分布1>#</a></h2><p>binomial probability distribution</p><p>二项分布是n重伯努利试验成功次数的离散概率分布，X服从二项分布记作X~B(n,p)，伯努利试验是只有两种可能结果的单次随机试验。</p><p>进行伯努利试验，成功（X=1）概率为p，失败（X=0）概率为1-p，随机变量X服从伯努利分布。</p><p>两点分布或称之为0-1分布</p><table><thead><tr><th>随机变量X</th><th>1</th><th>0</th></tr></thead><tbody><tr><td>概率P</td><td>p</td><td>1-p</td></tr></tbody></table><h2 id=20二项分布2>20二项分布2<a hidden class=anchor aria-hidden=true href=#20二项分布2>#</a></h2><h2 id=21二项分布3>21二项分布3<a hidden class=anchor aria-hidden=true href=#21二项分布3>#</a></h2><h2 id=22二项分布4>22二项分布4<a hidden class=anchor aria-hidden=true href=#22二项分布4>#</a></h2><h2 id=23期望值ex>23期望值E(x)<a hidden class=anchor aria-hidden=true href=#23期望值ex>#</a></h2><p>期望值就是总体均值。</p><h2 id=24二项分布的期望值>24二项分布的期望值<a hidden class=anchor aria-hidden=true href=#24二项分布的期望值>#</a></h2><p>二项分布就是一堆两点分布。</p><p>E(x)=np</p><p>D(x)=np(1-p)</p><p>期望值就是这些经过概率加权之后的和。</p><h2 id=25泊松过程1>25泊松过程1<a hidden class=anchor aria-hidden=true href=#25泊松过程1>#</a></h2><p>Poisson Distribution泊松分布其实来自二项分布。</p><p>泊松分布适用于描述单位时间/空间内随机事件发生的次数。</p><p><strong>泊松分布的使用场景，需要满足下面三个条件</strong>：</p><ol><li>单个事件发生与否，及发生概率是独立的；</li><li>已知给定区间（时间/空间）内，事件平均发生次数（发生率）；</li><li>发生的次数是有限的。</li></ol><h2 id=26泊松过程2>26泊松过程2<a hidden class=anchor aria-hidden=true href=#26泊松过程2>#</a></h2><p><a href=https://zhuanlan.zhihu.com/p/151773692># 离散型概率分布——泊松分布</a></p><p><strong>公式</strong>：假设K为给定区间内时间/空间的发生次数。参数λ为每个区间内平均发生次数 。概率可用公式表示如下：</p><p>$P(X=k)=\frac{e^{-\lambda}\lambda^k}{k!}$</p><p>推导过程需要用到第二个重要极限。</p><p><img loading=lazy src=https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost01/img/20230713113651.png></p><p><img loading=lazy src=https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost01/img/20230713113513.png></p><p><strong>示例</strong>：一个售后服务中心，平均每周接到A项目投诉2.5次。求下周没有接到A项目的投诉的概率是多少，接到A项目投诉3次的概率是多少。</p><p><img loading=lazy src=https://pic3.zhimg.com/80/v2-0a14934d8fb3624a2d0091152cce920e_1440w.webp></p><p>泊松分布求期望和方差非常好记，都为λ。</p><h4 id=泊松分布求期望>泊松分布求期望：<a hidden class=anchor aria-hidden=true href=#泊松分布求期望>#</a></h4><p><strong>公式</strong>：如果X~po(λ)，那么E(x)=λ。</p><p>示例：沿用上述A项目投诉的例子，在一周之内预计发生A项目的投诉次数为2.5次。</p><h4 id=泊松分布求方差>泊松分布求方差：<a hidden class=anchor aria-hidden=true href=#泊松分布求方差>#</a></h4><p><strong>公式</strong>：如果X~po(λ)，那么Var(x)=λ。</p><p><strong>示例</strong>：沿用上述A项目投诉的例子，在一周之内预计发生A项目的投诉次数的方差为2.5次。</p><h4 id=组合泊松分布>组合泊松分布：<a hidden class=anchor aria-hidden=true href=#组合泊松分布>#</a></h4><p><strong>公式</strong>：如果X<del>po(λ<strong>x</strong>)，且如果Y</del>po(λ<strong>y</strong>)，则：X +Y ~ po(λ<strong>x+<strong>λ</strong>y</strong>)</p><p><strong>示例</strong>：该售后服务中心，除了平均每周接到A项目的投诉2.5次，还会接到平均每周1次的B项目的投诉。下周总部会下来调查，希望收到的总投诉次数为0次，求这种情况的概率。</p><p><img loading=lazy src=https://pic4.zhimg.com/80/v2-463d88c1c31e771c1e6ad7da8bb2468f_1440w.webp></p><p>由结果可知，下周零投诉的概率为0.03。</p><h4 id=次数过多的二项分布使用泊松分布求解><strong>次数过多的二项分布使用泊松分布求解：</strong><a hidden class=anchor aria-hidden=true href=#次数过多的二项分布使用泊松分布求解>#</a></h4><p>之前在分享二项分布的时候，大家是否还记得猜箱子的小游戏？这个小游戏一共由4道题目组成，那么，假若这个小游戏有100道题目，甚至1000道题目呢？光是计算组合公式会让你算到头大。</p><p><strong>其实在遇到这种情况时，泊松分布也可以帮上忙。那么先来回顾下二项分布的期望与方差。</strong></p><p>二项分布的期望E(r)=np，方差Var(r)=npq，而泊松分布的期望和方差均为λ。此时我们需要这两种分布的期望和方差相近似，即np与npq近似相等的情况 。</p><p>由以上可知，当二项分布的n很大而p很小时，泊松分布可作为二项分布的近似，其中λ为np。通常当n≥20，p≤0.05时，就可以用泊松公式近似得计算。</p><p><strong>示例</strong>：借用二项分布文章中打靶的例子，假设打靶的数量为100次，求在这100次打靶中有3次能够打中10环的概率是多少 。</p><p><img loading=lazy src=https://pic1.zhimg.com/80/v2-cf90bf8031254246248c89f948dee57c_1440w.webp></p><p>在本题中，n=100，p=0.05，np=5，使用二项分布的泊松分布近似法得到X~po(<strong>5</strong>)，代入公式求出概率：</p><p><img loading=lazy src=https://pic1.zhimg.com/80/v2-7c09d36e4cca205f30cd31d9b9c940b0_1440w.webp></p><p>所以100次打靶中3次命中10环的概率为0.14。</p><h2 id=27大数定律>27大数定律<a hidden class=anchor aria-hidden=true href=#27大数定律>#</a></h2><p>The law of large numbers</p><p>样本量足够大时，样本均值接近期望值</p><p>赌徒谬误gambler&rsquo;s fallacy：一定次数试验后，如果正面数高于均值，则大数定律会让后面的正面数更少。</p><p>大数定律不关心前面发生的情况，收敛于期望值只是因为还有无限次收敛于期望值的试验，让前面的有限次实验可以忽略。不过买彩票和赌博的人并没有遵循这个原则。赌徒们不遵循这一原则，但赌场是知道的。短期内，少量样本时，有些人能打败庄家，但长期来看，庄家肯定是赢的，因为赌局的参数是他们定的。</p><h2 id=28正态分布excel练习>28正态分布Excel练习<a hidden class=anchor aria-hidden=true href=#28正态分布excel练习>#</a></h2><p><img alt=r loading=lazy src=https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost01/img/20230715092442.png></p><p>正态分布可以通过二项分布近似很好地得到。</p><p>central limit theorem中心极限定理即随机变量和的分布以正态分布为极限，即使这些试验的分布不是正态的。</p><h2 id=29正态分布介绍>29正态分布介绍<a hidden class=anchor aria-hidden=true href=#29正态分布介绍>#</a></h2><p>概率密度函数$p(x)=\frac{1}{\sigma \sqrt{2\pi}}exp(-\frac{(x-\mu)^2}{2\sigma^2})=\frac{1}{\sqrt{2\pi\sigma^2exp(z^2)}}$，其中标准z分数$z=\frac{x-\mu}{\sigma}$</p><p>概率就是对概率密度函数求定积分。</p><h2 id=30正态分布问题哪些是正态分布>30正态分布问题：哪些是正态分布？<a hidden class=anchor aria-hidden=true href=#30正态分布问题哪些是正态分布>#</a></h2><h2 id=31正态分布问题z分数>31正态分布问题：z分数<a hidden class=anchor aria-hidden=true href=#31正态分布问题z分数>#</a></h2><p>z score就是离均值有多少个标准差远</p><h2 id=32正态分布问题经验法则>32正态分布问题：经验法则<a hidden class=anchor aria-hidden=true href=#32正态分布问题经验法则>#</a></h2><p>empirical rule经验法则</p><p>高斯分布曲线取决于两个因素，即均值和标准差。分布的均值决定了图形中心位置，标准差决定了图像的高度与宽度，标准差小时，曲线“高瘦”，标准差大时，曲线“矮胖”。</p><p>sigma原则：数值分布在（μ-σ，μ+σ）中的概率为0.6526；</p><p>2sigma原则：数值分布在（μ-2σ，μ+2σ）中的概率为0.9544；</p><p><strong>3sigma原则：数值分布在（μ-3σ，μ+3σ）中的概率为0.9974；</strong></p><p><strong>基本上可以把区间（μ-3σ,μ+3σ）看作是随机变量X实际可能的取值区间，落在该区间之外的概率小于千分之三。</strong></p><p><img alt=r loading=lazy src=https://pic4.zhimg.com/80/v2-12e02c215536e1f4574e413eb7f5d0ef_1440w.webp></p><h2 id=33练习标准正态分布和经验法则>33练习：标准正态分布和经验法则<a hidden class=anchor aria-hidden=true href=#33练习标准正态分布和经验法则>#</a></h2><p>standard normal distribution X~N(0,1)</p><h2 id=34经验法则和z分数的进一步练习>34经验法则和z分数的进一步练习<a hidden class=anchor aria-hidden=true href=#34经验法则和z分数的进一步练习>#</a></h2><p>AP统计考试分数不是正态分布，有$\sigma和\mu$能求近似z-score。</p><p>z-score就是离均值有多少个标准差远，可以用在任何分布上，只要知道均值和标准差。</p><h2 id=35中心极限定理>35中心极限定理<a hidden class=anchor aria-hidden=true href=#35中心极限定理>#</a></h2><p><a href=https://zhuanlan.zhihu.com/p/545895865># 中心极限定理——概率论中最重要的结论之一</a></p><p>随着样本容量sample size趋于$\infty$，离散随机变量分布会趋于正态分布。</p><p>中心极限定理（central limit theorem/CLT）是概率论（probability theory）一个非常重要的结论，它指出在一定条件下，独立（independent）随机变量的标准化的（normalized）和随样本量（sample size）变大会趋向正态分布（normal distribution），即它的累积分布函数（cumulative distribution function/CDF）会收敛于标准正态分布（standard normal distribution）的CDF $N(x)=\int_{-\infty}^{x}\frac{1}{\sqrt{2\pi}}e^\frac{-x^2}{2}dx$</p><p>中心极限定理不要求随机变量本身是正态分布的，所以它带来一个非常重要的结果：在一定条件下，我们可以使用对正态分布成立的方法去应对非正态分布。比如，对于样本量 � 足够大时，二项分布（binomial distribution）$Bin(n,p)$ 可以用正态分布$N(np, np(1-p))$ 来近似。用具体事例来表达，如果我们抛 500 次硬币，由于每次抛硬币正面朝上的概率为 12 ，我们可以将正面朝上的数量近似地视作一个 $N(250,125)$ 的随机变量。中心极限定理有很多种版本，也有对于非独立变量的变式。在本篇文章中，我们将要介绍对于独立变量的中心极限定理的三个版本。有经典中心极限定理、林德伯格中心极限定理、李雅普诺夫中心极限定理、多维中心极限定理几种。</p><h2 id=36样本均值的抽样分布>36样本均值的抽样分布<a hidden class=anchor aria-hidden=true href=#36样本均值的抽样分布>#</a></h2><p><a href=https://onlinestatbook.com/>Online Statistics Education: An Interactive Multimedia Course of Study</a></p><p>sampling distribution of the sample mean</p><p><a href=https://zhuanlan.zhihu.com/p/84614017># 偏度和峰度</a></p><p>完美正态分布的偏度skew是0。如果偏度为正，意味着右侧尾部较长，即均值向左偏。</p><p>峰度kurtosis</p><p>正峰度——高</p><h3 id=偏度>偏度<a hidden class=anchor aria-hidden=true href=#偏度>#</a></h3><p>偏度（Skewness）可以用来度量随机变量概率分布的不对称性。</p><p>公式：</p><p>$S=\frac{1}{n}\sum_{i=1}^n [(\frac{X_i-\mu}{\sigma})^3]$</p><p>其中 $\mu$ 是均值， $\sigma$是标准差。</p><p>计算例子：</p><p>一组数据为1、2、2、4、1，均值为2，标准差约为1.22，所以偏度为</p><p>$S=15×[(1−21.22)^3+(2−21.22)^3+&mldr;+(1−21.22)^3]≈1.36$</p><p>几何意义：</p><p>偏度的取值范围为(-∞,+∞)</p><p>当偏度&lt;0时，概率分布图左偏。</p><p>当偏度=0时，表示数据相对均匀的分布在平均值两侧，不一定是绝对的对称分布。</p><p>当偏度>0时，概率分布图右偏。</p><p><img loading=lazy src=https://pic4.zhimg.com/80/v2-e04039aef878eeeef3cdd8a7e898073b_1440w.webp></p><p>例如上图中，两个概率分布图都是均值=0.6923，标准差=0.1685的，但是他们的形状是不一样的，左图偏度=-0.537，形状左偏，右图偏度=0.537，形状右偏。</p><h3 id=峰度>峰度<a hidden class=anchor aria-hidden=true href=#峰度>#</a></h3><p>峰度（Kurtosis）可以用来度量随机变量概率分布的陡峭程度。</p><p>公式：</p><p>$K=\frac{1}{n}\sum_{i=1}^n [(\frac{X_i-\mu}{\sigma})^4]$</p><p>其中 $\mu$ 是均值， $\sigma$是标准差。</p><p>几何意义：</p><p>峰度的取值范围为<code>[1,+∞)</code>，完全服从正态分布的数据的峰度值为 3，峰度值越大，概率分布图越高尖，峰度值越小，越矮胖。</p><p><img loading=lazy src=https://pic4.zhimg.com/80/v2-f7c874dd23c06a354d04558fa26a921f_1440w.webp></p><p>例如上图中，左图是标准正态分布，峰度=3，右图的峰度=4，可以看到右图比左图更高尖。</p><p>通常我们将峰度值减去3，也被称为超值峰度（Excess Kurtosis），这样正态分布的峰度值等于0，当峰度值>0，则表示该数据分布与正态分布相比较为高尖，当峰度值&lt;0，则表示该数据分布与正态分布相比较为矮胖。</p><h2 id=37样本均值的抽样分布2>37样本均值的抽样分布2<a hidden class=anchor aria-hidden=true href=#37样本均值的抽样分布2>#</a></h2><p>随着样本容量增大，分布会怎么变化？</p><p>当$n->\infty$时样本均值的抽样分布变为正态分布。一般来说，n=10或15就已经很接近正态分布了。</p><h2 id=38均值标准误差>38均值标准误差<a hidden class=anchor aria-hidden=true href=#38均值标准误差>#</a></h2><p>标准差standard deviation也被称为标准偏差，是描述各数据偏离平均数的距离的平均数，表征的是数据的离散程度。</p><p>标准误差Standard error表征的是单个统计量在多次抽样中呈现出的变异性。</p><p>前者表示数据本身的变异性，后者表征的是抽样行为的变异性。</p><p>随着样本容量的增大，会发生两件事：一是更接近正态分布，二是标准差更小。</p><p>样本均值抽样分布的方差等于原分布的方差除以n即$\sigma^2_{\bar x}=\frac{\sigma^2}{n}$</p><p>标准误差等于原分布标准差除以根号n即$\sigma_{\bar x}=\frac{\sigma}{\sqrt n}$</p><h2 id=39抽样分布例题>39抽样分布例题<a hidden class=anchor aria-hidden=true href=#39抽样分布例题>#</a></h2><p>The average male drinks 2L of water when active outdoors (with a standard deviation of .7L). You are planning a full day nature trip for 50 men and will bring 110L of water. What is the probability that you will run out?</p><p>P(run out) = P(usr more than 110L) = P(average water use per man is > 2.2L/m)</p><p>Sampling distribution of the sample mean when n=50</p><p>$\mu_{\bar x}=\mu=2L$</p><p>$\sigma_{\bar x}=\frac{\sigma}{\sqrt n}=\frac{0.7}{\sqrt 50}=0.099$</p><p>$z-score=\frac{X-\mu}{\sigma_{\bar x}}=\frac{2.2-2}{0.099}=2.02$</p><p>水不够的概率即是样本均值大于均值右侧2.020个标准差处的概率，根据z表格来求低于某值的概率。</p><p>P($\bar x$ will be more than 2.022 standard deviation above the mean)=1-0.9783=0.0217=2.17%</p><h2 id=40置信区间>40置信区间<a hidden class=anchor aria-hidden=true href=#40置信区间>#</a></h2><p>e.g. You sample 36 apples from your farm&rsquo;s harvest of over 200,000 apples. The mean weight of the sample is 112grams(with a 40 gram sample standard deviation). What is the probability that the mean weight of all 200,000 apples is within 100 and 124 grams?</p><p>即求总体均值落在样本均值左右12g范围内的概率。</p><p>P($\mu$ is within 12 of $\bar X$)=P($\bar X$ is within 12 of $\mu$)</p><p>重新写成这样之后，我们就会自然想到使用样本均值抽样分布。</p><p>P($\bar X$ is within 12 of $\mu$)=P($\bar X$ is within 12 of $\mu_{\bar x}$)</p><p>即求某一特定样本均值落在抽样分布均值左右12g范围内的概率。</p><p>$\sigma_{\bar x}=\frac{\sigma}{\sqrt n}=\frac{40}{\sqrt 36}=6.67$</p><p>$z-score=\frac{X-\mu}{\sigma_{\bar x}}=\frac{12}{6.67}=1.8$</p><p>根据z表格来求低于1.8个标准差的概率为0.9641。（这里只能从右边计算）</p><p>所求概率$P=2*(0.9641-0.5)=0.9282$</p><h2 id=41伯努利分布均值和方差的例子>41伯努利分布均值和方差的例子<a hidden class=anchor aria-hidden=true href=#41伯努利分布均值和方差的例子>#</a></h2><p>伯努利分布是两点分布。</p><p>离散分布期望值是各种可能值概率加权后的和。</p><table><thead><tr><th>支持与否</th><th>不支持0</th><th>支持1</th></tr></thead><tbody><tr><td>概率</td><td>0.4</td><td>0.6</td></tr></tbody></table><p>期望值=0.6</p><p>方差=$0.4*(0-0.6)^2+0.6*(1-0.6)^2=0.4*0.6=0.24$</p><h2 id=42伯努利分布均值和方差的公式>42伯努利分布均值和方差的公式<a hidden class=anchor aria-hidden=true href=#42伯努利分布均值和方差的公式>#</a></h2><p>$\mu = p$</p><p>$\sigma^2 = (1-p)<em>(0-p)^2+p</em>(1-p)^2=p(1-p)$</p><h2 id=43误差范围1>43误差范围1<a hidden class=anchor aria-hidden=true href=#43误差范围1>#</a></h2><p>随机调查100人的投票意愿，选B的（认为是事件1）有43人，选A的（认为是事件0）有57人。样本均值为0.43，方差为0.2475，样本标准差0.50，标准误差0.05。</p><p>找到这样一个合理置信区间，95%确信总体真实均值p值落在其中的区间</p><p>样本均值、抽样分布均值、总体均值是统计学中的重要概念，它们之间的区别如下：</p><ol><li><p>样本均值：是指从总体中随机抽取一个样本，并计算该样本中所有观测值的平均数。样本均值是对样本数据的一个统计描述，通常用作总体均值的估计值。</p></li><li><p>抽样分布均值：是指从总体中抽取多个样本，并计算所有样本均值的平均数。抽样分布均值是对样本均值的分布的一个描述，它的均值通常等于总体均值。</p></li><li><p>总体均值：是指总体中所有观测值的平均数。总体均值是一个未知参数，通常需要通过样本统计量来估计。</p></li></ol><p>总体均值是一个固定的未知参数，而样本均值和抽样分布均值是随机变量，它们的取值会随着不同的样本选择而变化。在统计学中，通过样本均值来估计总体均值是一种常见的方法，而抽样分布均值则用于评估样本均值的变异情况。</p><h2 id=44误差范围2>44误差范围2<a hidden class=anchor aria-hidden=true href=#44误差范围2>#</a></h2><p>找出一个合理的置信区间，95%的几率确信总体真实均值$\mu=p=\mu_{\bar x}$落在其中的区间</p><p>在正态分布中，样本均值落在两个标准差范围内的概率是95.44%。</p><p><strong>抽样分布的均值等于原分布的均值。抽样分布标准差是标准误差，不是样本标准差。</strong></p><p>误差范围margin of error是另一种描述置信区间confidence interval的方式。</p><ul><li>P($\bar X$ is within $2\sigma_{\bar x}$ of $\mu_{\bar X}$)=95.4%</li><li>P(p is within $2\sigma_{\bar x}$ of $\bar X$)=95.4%</li><li>P(p is with 2(0.05) of $\bar X$)=95%（从这里开始往下都是约等号）</li><li>P(p is with 2(0.05) of $\bar X$)=95%</li><li>P(p is with 0.1 of $\bar X$)=95%</li><li>P(p is within 0.33~0.53)=95%</li></ul><h2 id=45置信区间例题>45置信区间例题<a hidden class=anchor aria-hidden=true href=#45置信区间例题>#</a></h2><p>从6250名教师中随机抽取250人询问他们是否认为计算机是教室必备教学工具。其中，142名教师认为是必备的教学工具（记为事件1），108名教师认为不是必备的教学工具（记为事件0）。</p><table><thead><tr><th>\|X=1</th><th>X=0</th><th></th></tr></thead><tbody><tr><td>P</td><td>0.568</td><td>0.432</td></tr></tbody></table><p>均值为0.568，方差为0.246，样本标准差为0.496四舍五入为0.50，抽样分布标准差（标准误差）近似于样本标准差除以根号下样本容量，$\sigma_{\bar x}$=0.031</p><p>注：用p(1-p)计算得到的方差为0.245</p><p>1.Calculate a 99% confidence interval for the proportion of teachers who felt that computers are an essential teaching tool.</p><p>$0.99/2=0.495$</p><p>$0.495+0.5=0.995$</p><p>查询z-table发现0.995对应的数值为2.58，即有大概99%的概率使得样本均值落在抽样分布均值左右2.58个标准差（对应的概率为99.02%）范围内。抽样分布均值也就是原分布的均值，也就是认为计算机必备的老师占比p。这个值未知，但它有一个不错的估计值。</p><p><strong>我们有99%的把握认为样本均值0.568落在概率p左右0.08范围内，也即有99%的把握认为概率p落在0.568左右0.08范围内。</strong></p><p>置信区间为0.488~0.648，我们相信有99%几率真实概率p在这里两个数字之间。</p><p>2.How could the survey be changed to narrow the confidence interval but to maintain the 99% confidence interval?</p><p><strong>保持99%置信水平的前提下如何缩小置信区间？抽取更大样本即可。</strong></p><p>置信区间是指对于一个总体参数（比如总体均值或总体比例），基于样本数据，计算出的一个区间，使得该区间内包含该总体参数真实值的概率达到预先设定的置信水平。换句话说，置信区间是对总体参数真实值的一个估计，它告诉我们该估计的可靠程度。例如，假设我们想要估计某个产品的平均销售量。我们可以从该产品的销售记录中随机抽取一些样本，计算出样本均值和样本标准差。然后，我们可以使用样本均值和样本标准差，基于正态分布理论，计算出一个置信区间。例如，如果我们设置置信水平为95%，那么该置信区间将会包含95%的情况下真实的总体均值。这个区间的端点称为置信下限和置信上限。置信区间的宽度取决于样本大小、置信水平和总体标准差等因素。置信水平越高，置信区间就越宽；样本容量越大，置信区间就越窄；总体标准差越小，置信区间就越窄。置信区间是统计推断的重要工具，它可以帮助我们对总体参数的真实值做出合理的推断和决策。</p><p><strong>样本容量越大，抽样分布标准差就越小，置信区间通常就越窄。</strong></p><p>这是因为样本容量的增加会减小样本均值和总体均值之间的差异，从而使得置信区间变窄。具体而言，当样本容量增加时，样本均值的方差会减小，因此样本均值周围的误差也会减小，这就会导致置信区间的宽度减小。同时，当样本容量增加时，抽样分布的形状会趋近于正态分布，这也会使得置信区间变窄。需要注意的是，当总体标准差或置信水平固定时，样本容量越大，置信区间就越窄。但是，如果置信水平随样本容量的增加而提高，那么置信区间的变化可能会更加复杂。此外，当总体标准差未知时，使用样本标准差来计算置信区间时，样本容量的增加会使得样本标准差和抽样分布的自由度变化，这也需要考虑到。因此，总体标准差、置信水平、样本容量等因素的变化都会对置信区间的宽度产生影响，需要在实际问题中具体分析和判断。</p><h2 id=46小样本容量置信区间>46小样本容量置信区间<a hidden class=anchor aria-hidden=true href=#46小样本容量置信区间>#</a></h2><p>样本容量&lt;30通常被认为是糟糕的估计。</p><p>7个病人服药后血压分别上升了1.5, 2.9, 0.9, 3.9, 3.2, 2.1和1.9。Construct a 95% confidence interval for the true expected blood pressure increase for all patients in a population.</p><p>均值为2.34，标准差为1.04，$\sigma_{\bar x}$=0.39</p><p>这个视频里要讲的是，我们关注抽样分布，以此来生成区间。这里抽样分布不能像原来那样认为是正态分布使用中心极限定理之类的。我们需要改变抽样分布，不再假设是正态分布。我们假设是所谓的t分布。可以认为t分布是专门为更好估计小容量样本的置信区间所设计的。</p><p>t分布是一种概率分布，通常用于在样本容量较小的情况下进行总体参数的推断。t分布由英国统计学家威廉·塞奇威克（William Sealy Gosset）于西元1908年提出，因此也被称为“塞奇威克t分布”。t分布的形状类似于正态分布，但是相比于正态分布，它的峰度较低，而且尾部较厚。这是因为t分布的概率密度函数是基于样本标准差来计算的，而样本标准差本身是一个不稳定的估计量，其方差会随着样本容量的减小而增加。因此，在样本容量较小的情况下，t分布的形状会更加扁平和宽，以保证在总体均值未知时，对样本均值的推断更加准确。t分布的参数是自由度（degrees of freedom，df），自由度是指用于计算样本标准差的样本数量减去1。自由度越大，t分布就越接近于正态分布。在实践中，t分布通常用于构建置信区间或进行假设检验，以便对总体参数进行推断。</p><p>计算t分布的置信区间通常需要以下步骤：</p><ol><li><p>确定置信水平（confidence level）和自由度（degrees of freedom，df）。通常情况下，置信水平取值为95%或99%，自由度的计算方法取决于具体的问题，例如在单样本t检验中，自由度为n-1，其中n为样本容量。</p></li><li><p>计算样本均值（sample mean）和样本标准差（sample standard deviation）。样本均值是指样本中所有观测值的平均数，样本标准差是指样本中所有观测值与样本均值的差的平方和的平均数的平方根。</p></li><li><p>计算t值（t statistic）。t值是指样本均值与总体均值之间的差异除以标准误差（standard error）的比值，其中标准误差是指样本标准差除以样本容量的平方根。t值的计算公式为：</p></li></ol><p>t = (sample mean - population mean) / (sample standard deviation / sqrt(sample size))</p><p>其中，sample mean为样本均值，population mean为总体均值，sample standard deviation为样本标准差，sample size为样本容量。</p><ol start=4><li><p>根据置信水平和自由度，查找t分布表（或使用计算机软件）得到t临界值（t critical value）。</p></li><li><p>计算置信区间。置信区间可以通过以下公式计算：</p></li></ol><p>confidence interval = sample mean ± t临界值 × (sample standard deviation / sqrt(sample size))</p><p>其中，sample mean为样本均值，t临界值为根据置信水平和自由度从t分布表或计算机软件中查找得到的t值，sample standard deviation为样本标准差，sample size为样本容量。</p><p>通过以上步骤，可以得到t分布的置信区间，该区间表示总体参数的真实值有一定的概率落在该区间内。需要注意的是，计算t分布的置信区间时，需要满足一些假设条件，例如样本来自正态分布总体或样本容量较大等，否则计算结果可能不可靠。</p><p>置信水平为95%，自由度为6，查询t表格（该分布关于中轴对称，所以叫双侧。单侧表示一直到特定值的累积百分比。本题是对称的，用two-sided。）此时对应两侧2.447个标准差。t表格中说的标准差是通过样本标准差得到的估计值。</p><p>$\sigma_{\bar x}$=0.39，$\sigma_{\bar x}\times 2.447=0.96$，置信区间为1.38~3.30</p><p>说置信区间是因为这都是估计值。</p><h2 id=47假设检验和p值>47假设检验和p值<a hidden class=anchor aria-hidden=true href=#47假设检验和p值>#</a></h2><p>假设检验需要两个假设，一个是原假设（null hypothesis），另一个是备择假设（alternative hypothesis）。</p><p>原假设是一个被假定的基准假设，通常表示研究者想要测试的“无效”或“无差异”的情况。在进行假设检验时，我们会假定原假设为真，并通过数据来判断是否拒绝原假设。</p><p>备择假设则是对原假设的补充或对立假设，通常表示研究者想要证明的“有效”或“有差异”的情况。如果拒绝原假设，则可以接受备择假设。</p><p>因此，假设检验需要两个假设来进行比较和决策。通过比较数据与原假设的符合程度，我们可以判断是否有足够的证据来拒绝原假设，从而接受备择假设。</p><p>p值是指在假设检验中，根据样本数据计算出的一个概率值，表示在原假设为真的情况下，出现观测结果或更极端结果的概率。p值越小，代表观测到的数据与原假设不一致的可能性越大。</p><p>p值的主要作用是帮助我们做出关于原假设是否应被拒绝的决策。通常，我们会预先设定一个显著性水平（significance level）作为决策的标准，一般为0.05或0.01。如果计算出的p值小于显著性水平，则拒绝原假设，认为观测到的数据与原假设不一致；反之，则接受原假设。</p><p>除了用于决策的作用，p值还可以提供一些定量的信息。例如，p值越小，代表观测到的数据与原假设的差异越明显，可能性越小；而p值越大，则表示观测到的数据与原假设的差异越小，可能性越大。</p><p>需要注意的是，p值只能提供关于原假设是否应被拒绝的决策和一些定量信息，而不能确定原假设是否真实或备择假设是否正确。因此，在解释p值时，需要结合具体的实际背景和领域知识，进行综合分析。</p><p>例：已知没有注射药物的老鼠平均反应时间是1.2秒，100只注射药物的老鼠的平均反应时间为1.05秒，样本标准差为0.5秒。药物对反应时间有影响吗？</p><p>这里我们需要建立两个假设。</p><p>第一个假设是原假设（null hypothesis） H0: 药物对反应时间没影响</p><p>第二个假设是备择建设（alternative hypothesis）H：药物对反应时间有影响</p><p>假设Ho为真，然后求样本均值1.05，标准差0.5这一结果的概率，如果这个概率特别小，则认为原假设为假。</p><p>抽样分布均值=总体均值</p><p>抽样分布标准差等于总体标准差除以根号下样本容量，而总体标准差近似于样本标准差。</p><p>z-score = 3</p><p>根据经验法则，均值左右3个标准差内的概率为99.7%。</p><p>得到样本均值1.05，标准差0.5这一结果甚至更极端结果的概率为0.3%，这个概率特别小，因此我们认为原假设为假。</p><p>很多论文中，得到零假设中这种极端情况甚至更极端情况的概率称为p值。本题中p值为0.003。</p><h2 id=48单侧检验和双侧检验>48单侧检验和双侧检验<a hidden class=anchor aria-hidden=true href=#48单侧检验和双侧检验>#</a></h2><p>单侧检验和双侧检验是假设检验中常用的两种检验方式。</p><p>单侧检验（one-tailed test）是指在假设检验中，备择假设只包含一个方向的偏差，例如只考虑检验均值是否大于某个特定值，或者只考虑检验均值是否小于某个特定值。单侧检验所关心的只是一个方向的差异，因此在计算p值时，只需要考虑备择假设的一个方向即可。</p><p>双侧检验（two-tailed test）是指在假设检验中，备择假设包含两个方向的偏差，例如考虑检验均值是否与某个特定值不同，即既可能大于特定值，也可能小于特定值。双侧检验所关心的是两个方向的差异，因此在计算p值时，需要将备择假设的两个方向都考虑进去。</p><p>在进行单侧检验或双侧检验时，需要根据具体的实际背景和研究问题来确定使用哪种检验方式。如果研究者只关心一个方向的差异，可以选择单侧检验；如果研究者关心两个方向的差异，需要选择双侧检验。此外，在进行假设检验时，还需要注意选择适当的显著性水平和合适的假设检验方法，以得到准确、可靠的结果。</p><p>上题中我们只能说药物有一定效果，用药后的均值同原均值不一样，但没说增加还是减少了反应时间。</p><p>检验是否存在效果，这是双侧检验。</p><p>检验是否能减少平均反应时间，这是单侧检验。if H0, P(result lowers than 1.05s)=0.0015</p><h2 id=49z统计量vst统计量>49z统计量VSt统计量<a hidden class=anchor aria-hidden=true href=#49z统计量vst统计量>#</a></h2><p>$z统计量=\frac{\bar X -\mu_{\bar X}}{\frac{\sigma}{\sqrt n}} =\frac{\bar X -\mu_{\bar X}}{\frac{S}{\sqrt n}}$（正态分布、样本容量>30）</p><p>$t统计量=\frac{\bar X -\mu_{\bar X}}{\frac{S}{\sqrt n}}$（t分布、样本容量小）</p><h2 id=50-第一型错误>50 第一型错误<a hidden class=anchor aria-hidden=true href=#50-第一型错误>#</a></h2><p>第一型错误（Type I error）是指在假设检验中，拒绝了原假设，但实际上原假设是正确的，也就是错误地认为存在某种差异或效应。第一型错误通常用α表示，也称为显著性水平。</p><p>在假设检验中，我们需要设定一个显著性水平，通常为0.05或0.01，作为决策的标准。如果计算出的p值小于显著性水平，我们会拒绝原假设，认为观测到的数据与原假设不一致，也就是存在某种差异或效应。但如果实际上原假设是正确的，那么我们就会犯第一型错误，错误地认为存在差异或效应。</p><p>第一型错误是假设检验中一个比较严重的错误，因为它会导致我们得出错误的结论，浪费研究资源，也可能对决策产生严重后果。因此，在进行假设检验时，需要设定适当的显著性水平，并根据具体实际情况进行综合分析，以减少第一型错误的概率。</p><p>第一型错误和第二型错误是假设检验中两种不同类型的错误。</p><p>第一型错误（Type I error）是指拒绝原假设，但实际上原假设是正确的，也就是错误地认为存在某种差异或效应。第一型错误的概率通常用α表示，也称为显著性水平。</p><p>第二型错误（Type II error）是指接受原假设，但实际上原假设是错误的，也就是错误地认为不存在某种差异或效应。第二型错误的概率通常用β表示。</p><p>可以看出，第一型错误和第二型错误的区别在于错误的方向不同。第一型错误是错误地拒绝了原假设，而第二型错误是错误地接受了原假设。</p><p>在假设检验中，我们需要设定一个显著性水平作为决策的标准，以判断是否拒绝原假设。但在实际应用中，往往存在着一定的风险和成本，例如错失某种重要的差异或效应，或者浪费研究资源。因此，在进行假设检验时，需要综合考虑第一型错误和第二型错误，并选择适当的显著性水平和样本大小，以尽可能降低两种错误的概率。</p><p>在假设检验中，设定显著性水平是做出决策的关键因素之一。通常，显著性水平设定为0.05或0.01，这表示在原假设为真的情况下，出现观测结果或更极端结果的概率不超过5%或1%。显著性水平越小，代表拒绝原假设的标准越高，对差异或效应的要求也越高，但可能会导致第二型错误的概率增加。</p><p>设定显著性水平时，需要考虑具体的实际背景和研究问题，以及假设检验的目的和要求。如果研究对象是生命、财产等重大事项，或决策后果十分严重，需要设定更高的显著性水平，以尽可能降低第一型错误的概率；如果研究对象是对差异或效应的要求不高，或者样本量比较大，可以适当降低显著性水平，以降低第二型错误的概率。</p><p>此外，还需要考虑假设检验的类型和样本大小等因素。例如，在单侧检验中，显著性水平需要分配给备择假设的一个方向；在样本量较小的情况下，需要设定更高的显著性水平，以尽可能避免漏诊。</p><p>总之，设定显著性水平需要综合考虑各种因素，并根据具体情况进行灵活调整，以得到准确、可靠的假设检验结果。</p><h2 id=51小样本假设检验>51小样本假设检验<a hidden class=anchor aria-hidden=true href=#51小样本假设检验>#</a></h2><p>例题：The mean emission of all engines of a new design needs to be below 20 ppm if the design is to meet new emission requirements. Ten engines are manufactured for testing purposes, and the emission level of each is determined. The emission data is :</p><p>15.6 16.2 22.5 20.5 16.4 19.4 16.6 17.9 12.7 13.9</p><p>Does tje data supply sufficient evidence to conclude that this type of engine meets the new standard? Assume we are willing to risk a Type I error with probability = 0.01</p><p>均值=17.17标准差为2.98</p><p>H0：不满足标准$\mu=20ppm$</p><p>H1：满足标准即实际均值低于20ppm（$\mu&lt; 20ppm$</p><p><strong>先认为原假设H0成立，如果样本均值得到17.17的概率小于1%，我们就拒绝原假设</strong></p><p>$t=\frac{17.17-20}{\frac{2.98}{\sqrt 10}}=-3.00$</p><p><img loading=lazy src=https://cdn.jsdelivr.net/gh/Rosefinch-Midsummer/MyImagesHost01/img/20230720113806.png></p><p><strong>由对称性，查表知单侧t临界值为-2.8214，即t值小于-2.8214的概率是1%。我们算出的t值是-3.00，这显然进入了让我们拒绝原假设的区域，t值得到-3.00的概率比1%还小，所以我们可以相对可靠地拒绝原假设，接受备择假设即满足排放标准。而且这里犯第一型错误的概率低于1%。</strong></p><h2 id=52t统计量置信区间>52t统计量置信区间<a hidden class=anchor aria-hidden=true href=#52t统计量置信区间>#</a></h2><p>计算t分布的置信区间通常需要以下步骤：</p><ol><li><p>确定置信水平（confidence level）和自由度（degrees of freedom，df）。通常情况下，置信水平取值为95%或99%，自由度的计算方法取决于具体的问题，例如在单样本t检验中，自由度为n-1，其中n为样本容量。</p></li><li><p>计算样本均值（sample mean）和样本标准差（sample standard deviation）。样本均值是指样本中所有观测值的平均数，样本标准差是指样本中所有观测值与样本均值的差的平方和的平均数的平方根。</p></li><li><p>计算t值（t statistic）。t值是指样本均值与总体均值之间的差异除以标准误差（standard error）的比值，其中标准误差是指样本标准差除以样本容量的平方根。t值的计算公式为：</p></li></ol><p>t = (sample mean - population mean) / (sample standard deviation / sqrt(sample size))</p><p>其中，sample mean为样本均值，population mean为总体均值，sample standard deviation为样本标准差，sample size为样本容量。</p><ol start=4><li><p>根据置信水平和自由度，查找t分布表（或使用计算机软件）得到t临界值（t critical value）。</p></li><li><p>计算置信区间。置信区间可以通过以下公式计算：</p></li></ol><p>confidence interval = sample mean ± t临界值 × (sample standard deviation / sqrt(sample size))</p><p>其中，sample mean为样本均值，t临界值为根据置信水平和自由度从t分布表或计算机软件中查找得到的t值，sample standard deviation为样本标准差，sample size为样本容量。</p><p>通过以上步骤，可以得到t分布的置信区间，该区间表示总体参数的真实值有一定的概率落在该区间内。需要注意的是，计算t分布的置信区间时，需要满足一些假设条件，例如样本来自正态分布总体或样本容量较大等，否则计算结果可能不可靠。</p><p>t分布通常在样本容量较小的情况下使用。这是因为在小样本情况下，往往我们无法准确知道总体的标准差，所以我们使用样本标准差代替，这就引入了更多的不确定性，t分布就是在这种情况下用来估计未知总体均值的一种方法。但是，尽管t分布常常用于小样本量的情况，但也不是说在大样本量的情况下就不能使用。实际上，当样本量增大时，t分布会逐渐接近正态分布。所以，如果样本量较大，使用t分布和正态分布的结果差异通常很小，可以视为可忽略不计。另外，正如你所提到的，使用t分布需要满足一些前提假设，其中一个重要的假设是样本来自正态分布的总体。如果这个假设不满足，t分布可能就不是一个好的选择。</p><p>总的来说，t分布是一个在特定情况下使用的工具，其适用性取决于样本大小、样本来源等因素。</p><p>置信水平为95%，自由度为9，查询t表格（该分布关于中轴对称，所以叫双侧。单侧表示一直到特定值的累积百分比。本题是对称的，用two-sided。）此时对应两侧2.262个标准差。t表格中说的标准差是通过样本标准差得到的估计值。</p><p>$\sigma_{\bar x}$=17.17，$\sigma_{\bar x}\times 2.262=2.13$，置信区间为15.04~19.30</p><p>说置信区间是因为这都是估计值。</p><h2 id=53大样本占比假设检验>53大样本占比假设检验<a hidden class=anchor aria-hidden=true href=#53大样本占比假设检验>#</a></h2><p>例：We want to test the hypothesis that more than 30% of U.S. households have Internet access( with a significance level of 5%). We collect a sample of 150 households and find that 57 access.</p><p>要进行假设检验，首先要设定零假设和备择建设。零假设也就是要检验的内容不正确，这里零假设是美国家庭总体的互联网接入率小于等于30%。备择假设和要检验的一致即接入率大于30%。</p><p>然后我们要根据零假设得到一个总体中的占比值p，在这个假设下，看样本中150户中57户接入互联网的概率是多少？如果该概率小于5%，小于我们的显著性水平，那么我们就能拒绝零假设，接受备择假设。</p><p>一开始假设零假设是正确的，根据该假设，我们得到总体均值$\mu$或者说总体占比p，伯努利分布中$\mu=p$。我要选择的这个占比值需要尽可能让得到这种情况的概率最大。得到样本中这种情况的概率现在还不知道。样本占比0.38，总体占比为0.3。</p><p>根据伯努利分布，总体标准差$\sigma_{H_0}=\sqrt{(0.3)\times(0.7)}=\sqrt{0.21}$</p><p>根据二项分布，np>5，n(1-p)>5</p><p>样本占比分布的标准差$\sigma_{\bar P}=\frac{\sigma_{H_0}}{\sqrt{150}}=0.037$</p><p>$zscore=\frac{\bar P - \mu_{\bar P}}{\sigma_{\bar P}}=2.14$</p><p>我们关心的单侧分布得到这个z统计量的概率是多于还是少于5%，如果少于5%，我们将拒绝零假设，接受备择假设。</p><p>根据z-table，zscore对应的概率为0.9834，1-0.9834&lt;0.05，拒绝零假设，接受备择假设。</p><p><img alt=z-table loading=lazy src=https://pic2.zhimg.com/80/v2-f584977f6a44a62ad26c88214938cfbd_1440w.webp></p><h2 id=54随机变量之差的方差>54随机变量之差的方差<a hidden class=anchor aria-hidden=true href=#54随机变量之差的方差>#</a></h2><p>independent random variables X,Y</p><p>$E(x)=\mu_x$</p><p>$Var(x)=E((X-\mu_x)^2)=\sigma_x^2$ X的方差等于X离其均值距离平方的期望值</p><p>Z=X+Y==>E(Z)=E(X)+E(Y)</p><p>Var(Z)=Var(X)+Var(Y)</p><p>Z=X-Y==>E(Z)=E(X)-E(Y)</p><p>Var(Z)=Var(X)+Var(-Y)=Var(X)+Var(Y)</p><p>$E(a \times X+b)=aE(X)+b$</p><p>$D(a \times X+b)=a^2D(X)$</p><p>两个独立随机变量之差的方差等于两个方差之和</p><h2 id=55样本均值之差的分布>55样本均值之差的分布<a hidden class=anchor aria-hidden=true href=#55样本均值之差的分布>#</a></h2><p>Z=X-Y==>E(Z)=E(X)-E(Y)</p><p>Var(Z)=Var(X)+Var(-Y)=Var(X)+Var(Y)</p><p>样本均值抽样分布的方差$\sigma_{\bar x}^2=\frac{\sigma_x^2}{n}$</p><p>$\sigma_x^2$为实际总体分布的方差，而不是样本均值抽样分布的方差</p><p>$\sigma_{\bar y}^2=\frac{\sigma_y^2}{m}$</p><p>$\sigma_{\bar x- \bar y}^2=\sigma_{\bar x}^2+\sigma_{\bar y}^2=\frac{\sigma_x^2}{n}+\frac{\sigma_y^2}{m}$</p><h2 id=56均值之差的置信区间>56均值之差的置信区间<a hidden class=anchor aria-hidden=true href=#56均值之差的置信区间>#</a></h2><p>例：We&rsquo;re trying to test whether a new, low-fat diet actually helps obese people lose weight. 100 randomly assigned obese people are assigned to group 1 and put on the low fat diet. Another 100 randomly assigned obese people assigned to group 2 and put on a diet of approximately the same amount of food, but not as low in fat. After 4 months, the mean weight loss was 9.31 lbs. for group 1 (s=4.67) and 7.40 lbs.(s=4.04) for group 2.</p><p>low -fat group : ${\bar X_1}=9.31,s_1=4.67$</p><p>control group: ${\bar X_2}=7.40, s_2=4.04$</p><p>${\bar X_1}-{\bar X_2}=1.91$</p><p>$\sigma_{\bar x- \bar y}=\sqrt{\sigma_{\bar x}^2+\sigma_{\bar y}^2}=\sqrt{\frac{\sigma_x^2}{n}+\frac{\sigma_y^2}{m}}=\sqrt{\frac{s_1^2}{100}+\frac{s_2^2}{100}}=0.617$</p><p>95%置信区间</p><p>z-score对应的概率为97.5%</p><p>查阅z-table得到临界z值为1.96</p><p>有95%几率分布的实际均值落在1.91左右1.96个标准差内即置信区间为0.70~3.12</p><p>这里并非真正有95%几率实际均值的实际差值落在这个范围内，我们只是相信有95%的几率样本均值之差的实际期望值（实际均值的实际差值）落在0.7到3.12范围内，因为总体标准差或方差并非已知值。</p><p>这个置信区间其实也是总体期望值之差的置信区间。如果给所有可能的人第一种节食方式，给所有可能的人第二种节食方式，这将给出总体均值之差的置信区间。根据这个结果，也许第一种节食方式是有效的，因为即使是置信区间的下限处仍然比第二种节食方式减轻更多体重。</p><h2 id=57均值之差的置信区间的澄清>57均值之差的置信区间的澄清<a hidden class=anchor aria-hidden=true href=#57均值之差的置信区间的澄清>#</a></h2><p>$\mu_{\bar X - \bar Y}=\mu_{\bar X_1}-\mu_{\bar X_2}=\mu_1-\mu_2$</p><p>$\mu_1-\mu_2$是低脂节食同非低脂节食减肥效果的真实差异值，95%置信区间中，低脂节食方式更具减肥效果。</p><h2 id=58均值之差的假设检验>58均值之差的假设检验<a hidden class=anchor aria-hidden=true href=#58均值之差的假设检验>#</a></h2><p>零假设：减肥效果无差异即$\mu_1-\mu_2=0$</p><p>备择假设：（单侧）第一种节食方式减肥效果更好即$\mu_1-\mu_2>0$</p><p>5%显著性水平是说拒绝正确零假设的几率只有5%，也就是犯第一型错误的概率是5%。如果得到的概率小于5%，我们就拒绝原假设。</p><p>首先假设有一个标准化正态分布，这样才能求出临界z值，</p><p>根据z-table，95%对应的z值是1.65</p><p>$\sigma_{\bar x- \bar y}=\sqrt{\sigma_{\bar x}^2+\sigma_{\bar y}^2}=\sqrt{\frac{\sigma_x^2}{n}+\frac{\sigma_y^2}{m}}=\sqrt{\frac{s_1^2}{100}+\frac{s_2^2}{100}}=0.617$</p><p>如果第一种节食方式没效果的话，两个样本均值之差超过1.02的概率只有5%，但实际我们得到的均值的差值是1.91，这显然落在临界值之外，零假设前提下，得到这个的概率小于5%，得到这个差值的概率比显著性水平要低，我们拒绝零假设，接受备择假设即低脂节食方式确实能帮助减去更多体重。</p><h2 id=59总体占比的比较1>59总体占比的比较1<a hidden class=anchor aria-hidden=true href=#59总体占比的比较1>#</a></h2><p>讨论男女投票情况是否有差异。找一个$\bar P_1-\bar P_2$ 的95%置信区间</p><p>1000men 642 -1 rest -0 $\bar P_1=0.642$</p><p>sampling distribution of $\bar P_1$</p><p>$\sigma_{\bar P_1}^2=\frac{\sigma_{P_1^2}}{n}=\frac{P_1(1-P_1)}{1000}$</p><p>1000 women 591 -1 rest -0 $\bar P_2=0.591$</p><p>sampling distribution of $\bar P_2$</p><p>$\sigma_{\bar P_2}^2=\frac{\sigma_{P_2^2}}{n}=\frac{P_2(1-P_2)}{1000}$</p><p>$\sigma_{\bar P_1- \bar P_2}=\sqrt{\frac{P_1(1-P_1)}{1000}+\frac{P_2(1-P_2)}{1000}}=0.022$</p><h2 id=60总体占比的比较2>60总体占比的比较2<a hidden class=anchor aria-hidden=true href=#60总体占比的比较2>#</a></h2><p>$\bar P_1- \bar P_2=0.051$</p><p>conf: 95% chance that $\bar P_1- \bar P_2$ is within d(distance) of 0.051 也即 95%几率 0.051在均值$\bar P_1- \bar P_2$周围d之内</p><p><img alt=z-table loading=lazy src=https://pic2.zhimg.com/80/v2-f584977f6a44a62ad26c88214938cfbd_1440w.webp></p><p>95%的几率对应表中的97.5%，对应的zscore是1.96</p><p>$d=1.96\sigma_{\bar P_1- \bar P_2}=0.043$</p><p>有95%的几率总体占比之差在样本占比之差左右0.043范围内</p><p>投给某一特定候选人的男女总体占比之差的95%置信区间为<code>[0.008, 0.094]</code></p><p>该范围男性比女性占比更大</p><h2 id=61总体占比比较的假设检验>61总体占比比较的假设检验<a hidden class=anchor aria-hidden=true href=#61总体占比比较的假设检验>#</a></h2><p>检验投给某个候选人的男性占比同女性占比之间是否有显著不同</p><p>零假设是不存在差异，即$P_1- P_2=0$，P=0.6165</p><p>显著性水平定为5%，双侧检验，均值左侧和均值右侧很远处的极端情况，都将让我们拒绝零假设。zscore对应的累积概率是97.5%。</p><p>备择假设是存在差异。</p><p>$\sigma_{\bar P_1- \bar P_2}=\sqrt{\frac{2P(1-P)}{1000}}=0.0217$</p><p>$zscore=\frac{\bar P_1-\bar P_2-(P_1-P_2)}{\sigma_{\bar P_1- \bar P_2}}=2.34$</p><p>只有5%几率，零假设前提下，从z统计量中抽取的样本值大于1.96。</p><p>拒绝零假设，选择备择假设。</p><h2 id=62线性回归中的平方误差>62线性回归中的平方误差<a hidden class=anchor aria-hidden=true href=#62线性回归中的平方误差>#</a></h2><p>$y=mx+b$</p><p>$SE_{line}=(y_1-mx_1-b)^2+&mldr;+(y_n-mx_n-b)^2$</p><p>找m, b使得平方误差和SE最小</p><h2 id=63线性回归公式的推导1>63线性回归公式的推导1<a hidden class=anchor aria-hidden=true href=#63线性回归公式的推导1>#</a></h2><p>对上面的公式进行展开
$SE_{line}=(y_1^2+y_2^2+&mldr;+y_n^2)-2m(x_1y_1+x_2y_2+&mldr;+x_ny_n)-2b(y_1+y_2+&mldr;+y_n)+m^2(x_1^2+x_2^2+&mldr;+x_n^2+2mb(x_1+x_2+&mldr;+x_n)+nb^2$</p><h2 id=64线性回归公式的推导2>64线性回归公式的推导2<a hidden class=anchor aria-hidden=true href=#64线性回归公式的推导2>#</a></h2><p>n个点同直线之间平方误差之和</p><p>$SE_{line}=n{\bar {y^2}}-2mn\bar {xy}-2bn \bar y+m^2n{\bar {x^2}}+2mbn\bar x+nb^2$</p><h2 id=65线性回归公式的推导3>65线性回归公式的推导3<a hidden class=anchor aria-hidden=true href=#65线性回归公式的推导3>#</a></h2><p>最小化需要对m,b分别求偏导然后令两个式子等于0计算出对应的m,b</p><p>最小值点位于对m和b的斜率都为0的位置</p><p>$\frac{\partial SE_{line}}{m}=-2n\bar {xy}+2nm{\bar {x^2}}+2bn{\bar {x}}=0$</p><p>$\frac{\partial SE_{line}}{b}=-2n{\bar {y}}+2mn{\bar {x}}+2bn=0$</p><p>推导出$m{\bar {x}}+b={\bar {y}}$</p><p>$m\frac{{\bar {x^2}}}{{\bar {x}}}+b=\frac{{\bar {xy}}}{\bar {x}}$</p><p>可以发现两点都在直线上</p><h2 id=66线性回归公式的推导4>66线性回归公式的推导4<a hidden class=anchor aria-hidden=true href=#66线性回归公式的推导4>#</a></h2><p>上面得到的结果消元求解</p><p>$m=\frac{{\bar {x}{\bar {y}}-{\bar {xy}}}}{({\bar {x}})^2-{\bar {x^2}}}$</p><p>$b={\bar {y}}-m{\bar {x}}$</p><h2 id=67线性回归例题>67线性回归例题<a hidden class=anchor aria-hidden=true href=#67线性回归例题>#</a></h2><p>3个点（1，2）、（2，1），（4，3）</p><p>$m=\frac{7}{3}$</p><p>$b=1$</p><h2 id=68决定系数r2>68决定系数R2<a hidden class=anchor aria-hidden=true href=#68决定系数r2>#</a></h2><p>total variation in y: $SE_y = (y_1-\bar y)^2+(y_2-\bar y)^2+&mldr;+(y_n-\bar y)^2$</p><p>没被描述的波动$SE_{line}$，这个值越小，说明拟合效果越好</p><p>总波动种被直线描述的百分比即决定系数coefficient of determination，记作R2=$1-\frac{SE_{line}}{SE_{y}}$</p><h2 id=69线性回归例题2>69线性回归例题2<a hidden class=anchor aria-hidden=true href=#69线性回归例题2>#</a></h2><h2 id=70计算r2>70计算R2<a hidden class=anchor aria-hidden=true href=#70计算r2>#</a></h2><h2 id=71协方差和回归线>71协方差和回归线<a hidden class=anchor aria-hidden=true href=#71协方差和回归线>#</a></h2><p>两个随机变量之间的协方差covariance定义：两个随机变量离各自均值距离之积的期望值</p><p>$Cov(X,Y)=E[(X-E(X))(Y-E(Y))]=E(XY)-E[XE(Y)]-E(E(X)Y]+E[E(X)E(Y)]=E(XY)-E(X)E(Y)$</p><p>协方差近似表示$Cov(XY)={\bar {xy}}-{\bar {x}}{\bar {y}}$</p><p>$Var(X)=Cov(X,X)={\bar {x^2}}-({\bar {x}})^2$</p><p>$m=\frac{Cov(X,Y)}{Var(X)}$</p><h2 id=72-chi2分布>72 $\chi^2分布$<a hidden class=anchor aria-hidden=true href=#72-chi2分布>#</a></h2><p>卡方分布（英语：chi-square distribution, χ²-distribution，或写作χ²分布）是概率论与统计学中常用的一种概率分布。k个独立的标准正态分布变量的平方和服从自由度为k的卡方分布。卡方分布是一种特殊的伽玛分布，是统计推论中应用最为广泛的概率分布之一，例如假说检定和置信区间的计算。</p><p>由卡方分布延伸出来皮尔森卡方检定常用于：</p><pre><code>1.样本某性质的比例分布与母体理论分布的拟合优度（例如某行政机关男女比是否符合该机关所在城镇的男女比）；
2.同一母体的两个随机变量是否独立（例如人的身高与交通违规的关联性）；
3.二或多个母体同一属性的同质性检定（义大利面店和寿司店的营业额有没有差距）。（详见皮尔森卡方检定）
</code></pre><p><a href=https://zh.wikipedia.org/zh-hans/File:Chi-square_distributionPDF.png><img alt="Chi-square distributionPDF.png" loading=lazy src=https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Chi-square_distributionPDF.png/325px-Chi-square_distributionPDF.png></a></p><p>概率密度函数</p><p><a href=https://zh.wikipedia.org/zh-hans/File:Chi-square_distributionCDF.png><img alt="Chi-square distributionCDF.png" loading=lazy src=https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Chi-square_distributionCDF.png/325px-Chi-square_distributionCDF.png></a></p><p>累积分布函数</p><p>χ^2（卡方）分布是一种概率分布，通常用于统计学中的假设检验和置信区间构建。它可以用于比较观察值和期望值之间的差异，如在卡方检验中使用。在实际应用中，χ^2分布通常用于分析分类数据的差异和相关性。</p><p>χ^2分布的形状取决于自由度参数，自由度是一个与样本大小和数据维度有关的参数。当自由度越大时，χ^2分布趋向于正态分布，并且具有更小的方差。χ^2分布的平均值等于自由度，方差等于两倍自由度。</p><p>在假设检验中，可以将观察值与期望值之间的差异表示为χ^2统计量，然后将该统计量与χ^2分布进行比较，以判断观察值是否符合期望值。如果χ^2统计量的值很大，那么观察值与期望值之间的差异就很大，表明可能存在某种关系或者模型不适合该数据。</p><p>当我们想要测试一个硬币是否是公平的时候，我们可以进行一项硬币投掷实验。我们将硬币投掷n次，然后记录正面朝上的次数x。如果硬币是公平的，则我们期望正面朝上的次数为n/2。我们可以使用χ^2分布来判断观察值x是否符合期望值n/2。</p><p>具体地，我们可以计算出χ^2统计量：</p><p>χ^2 = Σ (observed - expected)^2 / expected</p><p>其中，observed是观察到的正面朝上的次数，expected是期望正面朝上的次数，即n/2。</p><p>假设我们将硬币投掷了10次，观察到正面朝上的次数为4。此时，期望正面朝上的次数为10/2=5。我们可以计算出χ^2统计量：</p><p>χ^2 = (4-5)^2/5 + (6-5)^2/5 = 0.2</p><p>接下来，我们可以使用χ^2分布表或者软件来查找自由度为1的χ^2分布，自由度为1表示我们只有一个自由度参数，即n-1=10-1=9。根据分布表或者软件，我们可以得到χ^2分布在自由度为1时的临界值为3.84。因为计算出的χ^2统计量0.2小于临界值3.84，所以我们不能拒绝原假设，即该硬币是公平的。</p><p>这个例子说明了如何使用χ^2分布来进行假设检验。如果χ^2统计量大于临界值，则我们可以拒绝原假设，即观察值不符合期望值，可能存在某种关系或者模型不适合该数据。</p><p><strong>卡方分布表</strong></p><p>p-value = 1- p_CDF.</p><p>χ2越大，p-value越小，则可信度越高。通常用p=0.05作为阈值，即95%的可信度。</p><p>常用的χ2与p-value表如下:</p><table><thead><tr><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>自由度k \ P value （概率）</td><td>0.95</td><td>0.90</td><td>0.80</td><td>0.70</td><td>0.50</td><td>0.30</td><td>0.20</td><td>0.10</td><td>0.05</td><td>0.01</td><td>0.001</td></tr><tr><td>1</td><td>0.004</td><td>0.02</td><td>0.06</td><td>0.15</td><td>0.46</td><td>1.07</td><td>1.64</td><td>2.71</td><td>3.84</td><td>6.64</td><td>10.83</td></tr><tr><td>2</td><td>0.10</td><td>0.21</td><td>0.45</td><td>0.71</td><td>1.39</td><td>2.41</td><td>3.22</td><td>4.60</td><td>5.99</td><td>9.21</td><td>13.82</td></tr><tr><td>3</td><td>0.35</td><td>0.58</td><td>1.01</td><td>1.42</td><td>2.37</td><td>3.66</td><td>4.64</td><td>6.25</td><td>7.82</td><td>11.34</td><td>16.27</td></tr><tr><td>4</td><td>0.71</td><td>1.06</td><td>1.65</td><td>2.20</td><td>3.36</td><td>4.88</td><td>5.99</td><td>7.78</td><td>9.49</td><td>13.28</td><td>18.47</td></tr><tr><td>5</td><td>1.14</td><td>1.61</td><td>2.34</td><td>3.00</td><td>4.35</td><td>6.06</td><td>7.29</td><td>9.24</td><td>11.07</td><td>15.09</td><td>20.52</td></tr><tr><td>6</td><td>1.63</td><td>2.20</td><td>3.07</td><td>3.83</td><td>5.35</td><td>7.23</td><td>8.56</td><td>10.64</td><td>12.59</td><td>16.81</td><td>22.46</td></tr><tr><td>7</td><td>2.17</td><td>2.83</td><td>3.82</td><td>4.67</td><td>6.35</td><td>8.38</td><td>9.80</td><td>12.02</td><td>14.07</td><td>18.48</td><td>24.32</td></tr><tr><td>8</td><td>2.73</td><td>3.49</td><td>4.59</td><td>5.53</td><td>7.34</td><td>9.52</td><td>11.03</td><td>13.36</td><td>15.51</td><td>20.09</td><td>26.12</td></tr><tr><td>9</td><td>3.32</td><td>4.17</td><td>5.38</td><td>6.39</td><td>8.34</td><td>10.66</td><td>12.24</td><td>14.68</td><td>16.92</td><td>21.67</td><td>27.88</td></tr><tr><td>10</td><td>3.94</td><td>4.86</td><td>6.18</td><td>7.27</td><td>9.34</td><td>11.78</td><td>13.44</td><td>15.99</td><td>18.31</td><td>23.21</td><td>29.59</td></tr></tbody></table><h2 id=73-皮尔逊chi2检验>73 皮尔逊$\chi^2$检验<a hidden class=anchor aria-hidden=true href=#73-皮尔逊chi2检验>#</a></h2><p>例题：检验给出的分布和观测的数据是否吻合</p><table><thead><tr><th>Day</th><th>M</th><th>T</th><th>W</th><th>W</th><th>F</th><th>S</th></tr></thead><tbody><tr><td>Expected%</td><td>10</td><td>10</td><td>15</td><td>20</td><td>30</td><td>15</td></tr><tr><td>Observed</td><td>30</td><td>14</td><td>34</td><td>45</td><td>57</td><td>20</td></tr></tbody></table><p>H0：给出的分布正确</p><p>H1：给出的分布不正确</p><p>显著性水平定为5%，如果$\chi ^2$统计量得到如此极端甚至更极端的概率大于显著性水平则接受H0</p><p>观测到的人数总和为200，根据分布，得到下面的期望值</p><table><thead><tr><th>Day</th><th>M</th><th>T</th><th>W</th><th>W</th><th>F</th><th>S</th></tr></thead><tbody><tr><td>Expected%</td><td>10</td><td>10</td><td>15</td><td>20</td><td>30</td><td>15</td></tr><tr><td>Observed</td><td>30</td><td>14</td><td>34</td><td>45</td><td>57</td><td>20</td></tr><tr><td>Expected</td><td>20</td><td>20</td><td>30</td><td>40</td><td>60</td><td>30</td></tr></tbody></table><p>具体地，我们可以计算出χ^2统计量：</p><p>χ^2 = Σ (observed - expected)^2 / expected=11.44</p><p>自由度=6-1=5（知道5条就能得知第6条）</p><p>临界$\chi^2$统计量为11.07&lt;11.44</p><p>拒绝原假设H0</p><p>显著性水平（significance level）是用于衡量统计推断中错误地拒绝原假设的概率。通常情况下，显著性水平被预先设定为一个小于1的数值，通常是0.05或0.01。这个数值表示如果原假设是真的，我们错误地拒绝原假设的概率，也就是犯第一类错误的概率。</p><p>但是，显著性水平并不能代表原假设的正确率。原假设的正确率是指原假设为真时，我们正确地接受原假设的概率。这个概率通常称为“功效”（power），并且取决于多种因素，包括样本大小、效应大小、显著性水平和统计方法等。</p><p>因此，在进行统计推断时，我们需要同时考虑显著性水平和功效，以便全面评估统计推断结果的可靠性和准确性。我们希望显著性水平尽可能小，以减少犯第一类错误的概率，但同时也需要考虑功效，以确保我们可以检测到真实的效应。</p><h2 id=74-列联表chi2检验>74 列联表$\chi^2$检验<a hidden class=anchor aria-hidden=true href=#74-列联表chi2检验>#</a></h2><p>contingency table列联表</p><table><thead><tr><th>\</th><th>Herb1</th><th>Herb2</th><th>Placebo安慰剂</th><th>患病或不患病的总人数</th></tr></thead><tbody><tr><td>sick</td><td>30</td><td>30</td><td>30</td><td>80（21%）</td></tr><tr><td>not sick</td><td>100</td><td>110</td><td>90</td><td>300（79%）</td></tr><tr><td>服用各种类型物品的总人数</td><td>120</td><td>140</td><td>120</td><td>380</td></tr><tr><td>预计患病人数</td><td>25.3</td><td>29.4</td><td>25.3</td><td></td></tr><tr><td>预计没患病人数</td><td>94.7</td><td>110.6</td><td>94.7</td><td></td></tr></tbody></table><p>H0：草药无效果</p><p>H1：有效果</p><p>显著性水平10%</p><p>$\chi^2=\frac{(20-25.3)^2}{25.3}+\frac{(30-29.4)^2}{29.4}+\frac{(20-25.3)^2}{25.3}+\frac{(100-94.7)^2}{94.7}+\frac{(110-110.6)^2}{110.6}+\frac{(100-94.7)^2}{94.7}=2.53$</p><p>列联表自由度=（行数-1）（列数-1）</p><p>本题自由度为2</p><p>4.60>2.53</p><p>根据现有数据，我们接受原假设。我们不能确定药草是否无效，但我们也不能说药草有效，我们无法拒绝原假设。虽然这不是100%正确，但我们无法拒绝它。</p><h2 id=75方差分析1计算总平方和>75方差分析1：计算总平方和<a hidden class=anchor aria-hidden=true href=#75方差分析1计算总平方和>#</a></h2><table><thead><tr><th>C1</th><th>C2</th><th>C3</th></tr></thead><tbody><tr><td>3</td><td>5</td><td>5</td></tr><tr><td>2</td><td>3</td><td>6</td></tr><tr><td>1</td><td>4</td><td>7</td></tr></tbody></table><p>总平均值为4</p><p>总平方和$SST=(3-4)^2+(2-4)^2+(1-4)^2+(5-4)^2+(5-4)^2+(4-4)^2+(5-4)^2+(6-4)^2+(7-4)^2=30$
自由度是数据数-1，因为知道了总均值，最后一个值可以计算出来。</p><p>这里自由度为$3\times3-1=9-1=8$</p><h2 id=76方差分析2组内和组间平方和>76方差分析2：组内和组间平方和<a hidden class=anchor aria-hidden=true href=#76方差分析2组内和组间平方和>#</a></h2><p>$\bar x_1=2,\bar x_2=4,\bar x_3=6$</p><p>组内平方和SSW：各点同各自组均值的距离平方之和</p><p>$SSW=(3-2)^2+(2-2)^2+(1-2)^2+(5-4)^2+(5-4)^2+(4-4)^2+(5-6)^2+(6-6)^2+(7-6)^2=6$</p><p>每组已知均值，每组n个数据，自由度为n-1</p><p>这里自由度$3\times(3-1)=6$</p><p>总波动中有这么多来自组内波动。</p><p>组间平方和SSB：来自均值之间的波动</p><p>$SSB=3\times(2-4)^2+3\times(4-4)^2+3\times(6-4)^2=24$</p><p>一般而言，如果有m组，m个均值，自由度为m-1。</p><p>这里自由度为3-1=2</p><p>$SST=SSW+SSB$</p><p>总自由度=m-1+m(n-1)=mn-1</p><h2 id=77方差分析3f统计量假设检验>77方差分析3：F统计量假设检验<a hidden class=anchor aria-hidden=true href=#77方差分析3f统计量假设检验>#</a></h2><p>F检定 (F-test)，亦称联合假设检定（joint hypotheses test）、变异数比率检验、方差齐性检验。它是一种在零假设（null hypothesis, H0）之下，统计值服从F-分布的检验。其通常是用来分析用了超过一个参数的统计模型，以判断该模型中的全部或一部分参数是否适合用来估计母体。</p><p>F检验这名称是由美国数学家兼统计学家George W. Snedecor命名，为了纪念英国统计学家兼生物学家罗纳德·费雪（Ronald Aylmer Fisher）。Fisher在1920年代发明了这个检验和F-分布，最初称为变异数比率（Variance Ratio）。</p><p>适用场合</p><p>检定一系列服从正态分布的母体是否有相同的标准差，此为最典型的F检定，此检定亦应用于变异数分析（ANOVA）中。</p><p>回归分析</p><ul><li>检定整条回归模型是否具有解释力，此即Overall F检定 (Overall F test) 。</li><li>检定回归模型中特定自变数是否具有解释力，即偏回归系数是否为零，此即偏F检定（Partial F test)。</li></ul><p>注意事项</p><p>F检验对于数据的正态性非常敏感，因此在进行变异数同质性（homoscedasticity）检定时，Levene检验, Bartlett检验或者Brown–Forsythe检验的稳健性都要优于F检验。 F检验还可以用于三组或者多组之间的均值比较，但是如果被检验的数据无法满足均是正态分布的条件时，该数据的稳健型会大打折扣，特别是当显著性水平比较低时。但是，如果数据符合正态分布，而且alpha值至少为0.05，该检验的稳健型还是相当可靠的。</p><p>若两个母体有相同的方差（方差齐性），那么可以采用F检验，但是该检验会呈现极端的非稳健性和非常态性，可以用t检验、巴特勒特检验等取代。</p><p>与其它统计值的关系</p><ul><li><strong>F检验的分子、分母其实各是一个卡方变数除以各自的自由度。</strong></li><li>F检定用以检定单一变数可否排除于模型外时，即进行只缩减单一变数之偏F检定（Partial F test）时，$F=t^{2}$。 可参见 线性回归偏回归系数β的t检验。</li></ul><p>这里存在一个无法衡量的总体均值，我们想知道是否有总体均值1=总体均值2=总体均值3？</p><p>H0：三组食物影响无差异</p><p>H1：有差异</p><p>显著性水平定为10%，临界F值是3.46（右尾检验，分子自由度为2，分母自由度为6）</p><p>Assume H0:</p><p>$F-statistic=\frac{\frac{SSB}{m-1}}{\frac{SSW}{m(n-1)}}$即组间平方和除以其自由度然后除以组内平方和除以其自由度</p><p>本题中F统计量为12</p><p>F分布其实是两个$\chi^2$分布之比</p><p>**<a href=http://socr.ucla.edu/htmls/dist/Fisher_Distribution.html>F Distribution Tables**</a> </p><p>The F distribution is a right-skewed distribution used most commonly in Analysis of Variance. When referencing the F distribution, the <strong>numerator degrees of freedom are always given first</strong>, as switching the order of degrees of freedom changes the distribution (e.g., F(10,12) does not equal F(12,10) ). For the four F tables below, the rows represent denominator degrees of freedom and the columns represent numerator degrees of freedom. The right tail area is given in the name of the table. For example, to determine the .05 critical value for an F distribution with 10 and 12 degrees of freedom, look in the 10 column (numerator) and 12 row (denominator) of the F Table for alpha=.05. F(.05, 10, 12) = 2.7534. You can use the <a href=http://socr.ucla.edu/htmls/dist/Fisher_Distribution.html>interactive F-Distribution Applet</a> to obtain more accurate measures.</p><p><strong>F Table for α = 0.10</strong></p><p><img alt=F_Distribution_Graph loading=lazy src=http://www.socr.ucla.edu/Applets.dir/F_Distrib_Pic.jpg>
<img alt=r loading=lazy src=http://www.socr.ucla.edu/Applets.dir/F_Distrib_Pic.jpg></p><table><thead><tr><th>\|分子df1=1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>12</th><th>15</th><th>20</th><th>24</th><th>30</th><th>40</th><th>60</th><th>120</th><th>∞</th><th></th></tr></thead><tbody><tr><td>分母df2=1</td><td>39.86346</td><td>49.50000</td><td>53.59324</td><td>55.83296</td><td>57.24008</td><td>58.20442</td><td>58.90595</td><td>59.43898</td><td>59.85759</td><td>60.19498</td><td>60.70521</td><td>61.22034</td><td>61.74029</td><td>62.00205</td><td>62.26497</td><td>62.52905</td><td>62.79428</td><td>63.06064</td><td>63.32812</td></tr><tr><td>2</td><td>8.52632</td><td>9.00000</td><td>9.16179</td><td>9.24342</td><td>9.29263</td><td>9.32553</td><td>9.34908</td><td>9.36677</td><td>9.38054</td><td>9.39157</td><td>9.40813</td><td>9.42471</td><td>9.44131</td><td>9.44962</td><td>9.45793</td><td>9.46624</td><td>9.47456</td><td>9.48289</td><td>9.49122</td></tr><tr><td>3</td><td>5.53832</td><td>5.46238</td><td>5.39077</td><td>5.34264</td><td>5.30916</td><td>5.28473</td><td>5.26619</td><td>5.25167</td><td>5.24000</td><td>5.23041</td><td>5.21562</td><td>5.20031</td><td>5.18448</td><td>5.17636</td><td>5.16811</td><td>5.15972</td><td>5.15119</td><td>5.14251</td><td>5.13370</td></tr><tr><td>4</td><td>4.54477</td><td>4.32456</td><td>4.19086</td><td>4.10725</td><td>4.05058</td><td>4.00975</td><td>3.97897</td><td>3.95494</td><td>3.93567</td><td>3.91988</td><td>3.89553</td><td>3.87036</td><td>3.84434</td><td>3.83099</td><td>3.81742</td><td>3.80361</td><td>3.78957</td><td>3.77527</td><td>3.76073</td></tr><tr><td>5</td><td>4.06042</td><td>3.77972</td><td>3.61948</td><td>3.52020</td><td>3.45298</td><td>3.40451</td><td>3.36790</td><td>3.33928</td><td>3.31628</td><td>3.29740</td><td>3.26824</td><td>3.23801</td><td>3.20665</td><td>3.19052</td><td>3.17408</td><td>3.15732</td><td>3.14023</td><td>3.12279</td><td>3.10500</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>6</td><td>3.77595</td><td>3.46330</td><td>3.28876</td><td>3.18076</td><td>3.10751</td><td>3.05455</td><td>3.01446</td><td>2.98304</td><td>2.95774</td><td>2.93693</td><td>2.90472</td><td>2.87122</td><td>2.83634</td><td>2.81834</td><td>2.79996</td><td>2.78117</td><td>2.76195</td><td>2.74229</td><td>2.72216</td></tr><tr><td>7</td><td>3.58943</td><td>3.25744</td><td>3.07407</td><td>2.96053</td><td>2.88334</td><td>2.82739</td><td>2.78493</td><td>2.75158</td><td>2.72468</td><td>2.70251</td><td>2.66811</td><td>2.63223</td><td>2.59473</td><td>2.57533</td><td>2.55546</td><td>2.53510</td><td>2.51422</td><td>2.49279</td><td>2.47079</td></tr><tr><td>8</td><td>3.45792</td><td>3.11312</td><td>2.92380</td><td>2.80643</td><td>2.72645</td><td>2.66833</td><td>2.62413</td><td>2.58935</td><td>2.56124</td><td>2.53804</td><td>2.50196</td><td>2.46422</td><td>2.42464</td><td>2.40410</td><td>2.38302</td><td>2.36136</td><td>2.33910</td><td>2.31618</td><td>2.29257</td></tr><tr><td>9</td><td>3.36030</td><td>3.00645</td><td>2.81286</td><td>2.69268</td><td>2.61061</td><td>2.55086</td><td>2.50531</td><td>2.46941</td><td>2.44034</td><td>2.41632</td><td>2.37888</td><td>2.33962</td><td>2.29832</td><td>2.27683</td><td>2.25472</td><td>2.23196</td><td>2.20849</td><td>2.18427</td><td>2.15923</td></tr><tr><td>10</td><td>3.28502</td><td>2.92447</td><td>2.72767</td><td>2.60534</td><td>2.52164</td><td>2.46058</td><td>2.41397</td><td>2.37715</td><td>2.34731</td><td>2.32260</td><td>2.28405</td><td>2.24351</td><td>2.20074</td><td>2.17843</td><td>2.15543</td><td>2.13169</td><td>2.10716</td><td>2.08176</td><td>2.05542</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>11</td><td>3.22520</td><td>2.85951</td><td>2.66023</td><td>2.53619</td><td>2.45118</td><td>2.38907</td><td>2.34157</td><td>2.30400</td><td>2.27350</td><td>2.24823</td><td>2.20873</td><td>2.16709</td><td>2.12305</td><td>2.10001</td><td>2.07621</td><td>2.05161</td><td>2.02612</td><td>1.99965</td><td>1.97211</td></tr><tr><td>12</td><td>3.17655</td><td>2.80680</td><td>2.60552</td><td>2.48010</td><td>2.39402</td><td>2.33102</td><td>2.28278</td><td>2.24457</td><td>2.21352</td><td>2.18776</td><td>2.14744</td><td>2.10485</td><td>2.05968</td><td>2.03599</td><td>2.01149</td><td>1.98610</td><td>1.95973</td><td>1.93228</td><td>1.90361</td></tr><tr><td>13</td><td>3.13621</td><td>2.76317</td><td>2.56027</td><td>2.43371</td><td>2.34672</td><td>2.28298</td><td>2.23410</td><td>2.19535</td><td>2.16382</td><td>2.13763</td><td>2.09659</td><td>2.05316</td><td>2.00698</td><td>1.98272</td><td>1.95757</td><td>1.93147</td><td>1.90429</td><td>1.87591</td><td>1.84620</td></tr><tr><td>14</td><td>3.10221</td><td>2.72647</td><td>2.52222</td><td>2.39469</td><td>2.30694</td><td>2.24256</td><td>2.19313</td><td>2.15390</td><td>2.12195</td><td>2.09540</td><td>2.05371</td><td>2.00953</td><td>1.96245</td><td>1.93766</td><td>1.91193</td><td>1.88516</td><td>1.85723</td><td>1.82800</td><td>1.79728</td></tr><tr><td>15</td><td>3.07319</td><td>2.69517</td><td>2.48979</td><td>2.36143</td><td>2.27302</td><td>2.20808</td><td>2.15818</td><td>2.11853</td><td>2.08621</td><td>2.05932</td><td>2.01707</td><td>1.97222</td><td>1.92431</td><td>1.89904</td><td>1.87277</td><td>1.84539</td><td>1.81676</td><td>1.78672</td><td>1.75505</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>16</td><td>3.04811</td><td>2.66817</td><td>2.46181</td><td>2.33274</td><td>2.24376</td><td>2.17833</td><td>2.12800</td><td>2.08798</td><td>2.05533</td><td>2.02815</td><td>1.98539</td><td>1.93992</td><td>1.89127</td><td>1.86556</td><td>1.83879</td><td>1.81084</td><td>1.78156</td><td>1.75075</td><td>1.71817</td></tr><tr><td>17</td><td>3.02623</td><td>2.64464</td><td>2.43743</td><td>2.30775</td><td>2.21825</td><td>2.15239</td><td>2.10169</td><td>2.06134</td><td>2.02839</td><td>2.00094</td><td>1.95772</td><td>1.91169</td><td>1.86236</td><td>1.83624</td><td>1.80901</td><td>1.78053</td><td>1.75063</td><td>1.71909</td><td>1.68564</td></tr><tr><td>18</td><td>3.00698</td><td>2.62395</td><td>2.41601</td><td>2.28577</td><td>2.19583</td><td>2.12958</td><td>2.07854</td><td>2.03789</td><td>2.00467</td><td>1.97698</td><td>1.93334</td><td>1.88681</td><td>1.83685</td><td>1.81035</td><td>1.78269</td><td>1.75371</td><td>1.72322</td><td>1.69099</td><td>1.65671</td></tr><tr><td>19</td><td>2.98990</td><td>2.60561</td><td>2.39702</td><td>2.26630</td><td>2.17596</td><td>2.10936</td><td>2.05802</td><td>2.01710</td><td>1.98364</td><td>1.95573</td><td>1.91170</td><td>1.86471</td><td>1.81416</td><td>1.78731</td><td>1.75924</td><td>1.72979</td><td>1.69876</td><td>1.66587</td><td>1.63077</td></tr><tr><td>20</td><td>2.97465</td><td>2.58925</td><td>2.38009</td><td>2.24893</td><td>2.15823</td><td>2.09132</td><td>2.03970</td><td>1.99853</td><td>1.96485</td><td>1.93674</td><td>1.89236</td><td>1.84494</td><td>1.79384</td><td>1.76667</td><td>1.73822</td><td>1.70833</td><td>1.67678</td><td>1.64326</td><td>1.60738</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>21</td><td>2.96096</td><td>2.57457</td><td>2.36489</td><td>2.23334</td><td>2.14231</td><td>2.07512</td><td>2.02325</td><td>1.98186</td><td>1.94797</td><td>1.91967</td><td>1.87497</td><td>1.82715</td><td>1.77555</td><td>1.74807</td><td>1.71927</td><td>1.68896</td><td>1.65691</td><td>1.62278</td><td>1.58615</td></tr><tr><td>22</td><td>2.94858</td><td>2.56131</td><td>2.35117</td><td>2.21927</td><td>2.12794</td><td>2.06050</td><td>2.00840</td><td>1.96680</td><td>1.93273</td><td>1.90425</td><td>1.85925</td><td>1.81106</td><td>1.75899</td><td>1.73122</td><td>1.70208</td><td>1.67138</td><td>1.63885</td><td>1.60415</td><td>1.56678</td></tr><tr><td>23</td><td>2.93736</td><td>2.54929</td><td>2.33873</td><td>2.20651</td><td>2.11491</td><td>2.04723</td><td>1.99492</td><td>1.95312</td><td>1.91888</td><td>1.89025</td><td>1.84497</td><td>1.79643</td><td>1.74392</td><td>1.71588</td><td>1.68643</td><td>1.65535</td><td>1.62237</td><td>1.58711</td><td>1.54903</td></tr><tr><td>24</td><td>2.92712</td><td>2.53833</td><td>2.32739</td><td>2.19488</td><td>2.10303</td><td>2.03513</td><td>1.98263</td><td>1.94066</td><td>1.90625</td><td>1.87748</td><td>1.83194</td><td>1.78308</td><td>1.73015</td><td>1.70185</td><td>1.67210</td><td>1.64067</td><td>1.60726</td><td>1.57146</td><td>1.53270</td></tr><tr><td>25</td><td>2.91774</td><td>2.52831</td><td>2.31702</td><td>2.18424</td><td>2.09216</td><td>2.02406</td><td>1.97138</td><td>1.92925</td><td>1.89469</td><td>1.86578</td><td>1.82000</td><td>1.77083</td><td>1.71752</td><td>1.68898</td><td>1.65895</td><td>1.62718</td><td>1.59335</td><td>1.55703</td><td>1.51760</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>26</td><td>2.90913</td><td>2.51910</td><td>2.30749</td><td>2.17447</td><td>2.08218</td><td>2.01389</td><td>1.96104</td><td>1.91876</td><td>1.88407</td><td>1.85503</td><td>1.80902</td><td>1.75957</td><td>1.70589</td><td>1.67712</td><td>1.64682</td><td>1.61472</td><td>1.58050</td><td>1.54368</td><td>1.50360</td></tr><tr><td>27</td><td>2.90119</td><td>2.51061</td><td>2.29871</td><td>2.16546</td><td>2.07298</td><td>2.00452</td><td>1.95151</td><td>1.90909</td><td>1.87427</td><td>1.84511</td><td>1.79889</td><td>1.74917</td><td>1.69514</td><td>1.66616</td><td>1.63560</td><td>1.60320</td><td>1.56859</td><td>1.53129</td><td>1.49057</td></tr><tr><td>28</td><td>2.89385</td><td>2.50276</td><td>2.29060</td><td>2.15714</td><td>2.06447</td><td>1.99585</td><td>1.94270</td><td>1.90014</td><td>1.86520</td><td>1.83593</td><td>1.78951</td><td>1.73954</td><td>1.68519</td><td>1.65600</td><td>1.62519</td><td>1.59250</td><td>1.55753</td><td>1.51976</td><td>1.47841</td></tr><tr><td>29</td><td>2.88703</td><td>2.49548</td><td>2.28307</td><td>2.14941</td><td>2.05658</td><td>1.98781</td><td>1.93452</td><td>1.89184</td><td>1.85679</td><td>1.82741</td><td>1.78081</td><td>1.73060</td><td>1.67593</td><td>1.64655</td><td>1.61551</td><td>1.58253</td><td>1.54721</td><td>1.50899</td><td>1.46704</td></tr><tr><td>30</td><td>2.88069</td><td>2.48872</td><td>2.27607</td><td>2.14223</td><td>2.04925</td><td>1.98033</td><td>1.92692</td><td>1.88412</td><td>1.84896</td><td>1.81949</td><td>1.77270</td><td>1.72227</td><td>1.66731</td><td>1.63774</td><td>1.60648</td><td>1.57323</td><td>1.53757</td><td>1.49891</td><td>1.45636</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>40</td><td>2.83535</td><td>2.44037</td><td>2.22609</td><td>2.09095</td><td>1.99682</td><td>1.92688</td><td>1.87252</td><td>1.82886</td><td>1.79290</td><td>1.76269</td><td>1.71456</td><td>1.66241</td><td>1.60515</td><td>1.57411</td><td>1.54108</td><td>1.50562</td><td>1.46716</td><td>1.42476</td><td>1.37691</td></tr><tr><td>60</td><td>2.79107</td><td>2.39325</td><td>2.17741</td><td>2.04099</td><td>1.94571</td><td>1.87472</td><td>1.81939</td><td>1.77483</td><td>1.73802</td><td>1.70701</td><td>1.65743</td><td>1.60337</td><td>1.54349</td><td>1.51072</td><td>1.47554</td><td>1.43734</td><td>1.39520</td><td>1.34757</td><td>1.29146</td></tr><tr><td>120</td><td>2.74781</td><td>2.34734</td><td>2.12999</td><td>1.99230</td><td>1.89587</td><td>1.82381</td><td>1.76748</td><td>1.72196</td><td>1.68425</td><td>1.65238</td><td>1.60120</td><td>1.54500</td><td>1.48207</td><td>1.44723</td><td>1.40938</td><td>1.36760</td><td>1.32034</td><td>1.26457</td><td>1.19256</td></tr><tr><td>∞</td><td>2.70554</td><td>2.30259</td><td>2.08380</td><td>1.94486</td><td>1.84727</td><td>1.77411</td><td>1.71672</td><td>1.67020</td><td>1.63152</td><td>1.59872</td><td>1.54578</td><td>1.48714</td><td>1.42060</td><td>1.38318</td><td>1.34187</td><td>1.29513</td><td>1.23995</td><td>1.16860</td><td>1.00000</td></tr></tbody></table><p><strong>F Table for α = 0.01</strong></p><table><thead><tr><th>\|df1=1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>12</th><th>15</th><th>20</th><th>24</th><th>30</th><th>40</th><th>60</th><th>120</th><th>∞</th><th></th></tr></thead><tbody><tr><td>df2=1</td><td>4052.181</td><td>4999.500</td><td>5403.352</td><td>5624.583</td><td>5763.650</td><td>5858.986</td><td>5928.356</td><td>5981.070</td><td>6022.473</td><td>6055.847</td><td>6106.321</td><td>6157.285</td><td>6208.730</td><td>6234.631</td><td>6260.649</td><td>6286.782</td><td>6313.030</td><td>6339.391</td><td>6365.864</td></tr><tr><td>2</td><td>98.503</td><td>99.000</td><td>99.166</td><td>99.249</td><td>99.299</td><td>99.333</td><td>99.356</td><td>99.374</td><td>99.388</td><td>99.399</td><td>99.416</td><td>99.433</td><td>99.449</td><td>99.458</td><td>99.466</td><td>99.474</td><td>99.482</td><td>99.491</td><td>99.499</td></tr><tr><td>3</td><td>34.116</td><td>30.817</td><td>29.457</td><td>28.710</td><td>28.237</td><td>27.911</td><td>27.672</td><td>27.489</td><td>27.345</td><td>27.229</td><td>27.052</td><td>26.872</td><td>26.690</td><td>26.598</td><td>26.505</td><td>26.411</td><td>26.316</td><td>26.221</td><td>26.125</td></tr><tr><td>4</td><td>21.198</td><td>18.000</td><td>16.694</td><td>15.977</td><td>15.522</td><td>15.207</td><td>14.976</td><td>14.799</td><td>14.659</td><td>14.546</td><td>14.374</td><td>14.198</td><td>14.020</td><td>13.929</td><td>13.838</td><td>13.745</td><td>13.652</td><td>13.558</td><td>13.463</td></tr><tr><td>5</td><td>16.258</td><td>13.274</td><td>12.060</td><td>11.392</td><td>10.967</td><td>10.672</td><td>10.456</td><td>10.289</td><td>10.158</td><td>10.051</td><td>9.888</td><td>9.722</td><td>9.553</td><td>9.466</td><td>9.379</td><td>9.291</td><td>9.202</td><td>9.112</td><td>9.020</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>6</td><td>13.745</td><td>10.925</td><td>9.780</td><td>9.148</td><td>8.746</td><td>8.466</td><td>8.260</td><td>8.102</td><td>7.976</td><td>7.874</td><td>7.718</td><td>7.559</td><td>7.396</td><td>7.313</td><td>7.229</td><td>7.143</td><td>7.057</td><td>6.969</td><td>6.880</td></tr><tr><td>7</td><td>12.246</td><td>9.547</td><td>8.451</td><td>7.847</td><td>7.460</td><td>7.191</td><td>6.993</td><td>6.840</td><td>6.719</td><td>6.620</td><td>6.469</td><td>6.314</td><td>6.155</td><td>6.074</td><td>5.992</td><td>5.908</td><td>5.824</td><td>5.737</td><td>5.650</td></tr></tbody></table><p>零假设前提下，得到如此极短的值得概率非常低，这个12比10%显著性水平的临界F统计量大太多。因此，我们拒绝原假设。</p><h2 id=附录如何使用临界-f-值计算器>附录如何使用临界 f 值计算器？<a hidden class=anchor aria-hidden=true href=#附录如何使用临界-f-值计算器>#</a></h2><p><a href=https://mathcracker.com/zh/f-%E4%B8%B4%E7%95%8C%E5%80%BC>计算器</a></p><p>首先,这里有一些关于 <em>F 分布概率的临界值</em> ：临界值是特定分布尾部的点,因此这些点到尾部的曲线下面积等于 α 的给定值。因此,对于双尾情况,临界值分别对应左右尾部的两个点,其性质为左尾部曲线下面积（从左临界点算起）与面积之和右尾曲线下等于给定的显着性水平 α。</p><p>在左尾情况下,临界值对应于分布左尾的点,其特性是左尾曲线下的面积（从临界点到左边）等于给定的显着性水平 α。</p><p>对于右尾情况,临界值对应于分布右尾的点,右尾曲线下的面积（从临界点向右）等于给定的显着性水平 α</p><p>我们有一系列临界值计算器,包括 <a href=https://mathcracker.com/zh/z%E5%85%B3%E9%94%AE%E5%80%BC>临界 z 值</a> , 临界的 <a href=https://mathcracker.com/zh/T%E5%85%B3%E9%94%AE%E5%80%BC>t值</a> ,仅举几例。</p><h2 id=78相关性和因果性>78相关性和因果性<a hidden class=anchor aria-hidden=true href=#78相关性和因果性>#</a></h2><p>correlation相关性：A和B有可能被同时观测到或者说B发生时A有可能同时发生</p><p>causality因果性：A导致B</p><h2 id=79演绎推理deductive-reasoning-1>79演绎推理deductive reasoning 1<a hidden class=anchor aria-hidden=true href=#79演绎推理deductive-reasoning-1>#</a></h2><p>演绎推理：寻找规律或趋势，然后推广。</p><p>三段式演绎推理</p><p>比如预测小镇人数。</p><p><strong>演绎推理（Deductive Reasoning）</strong></p><p>演绎推理来自于逻辑学，它是通过一般的原理或规则来推导出特定的结论。如果前提是真的，那么演绎推理的结论就必须是真的。例如，如果所有人都是有死亡的（前提），那么我也会死亡（结论）。这就是一个演绎推理的例子。在演绎推理中，前提的真实性决定了结论的真实性。</p><p><strong>归纳推理（Inductive Reasoning）</strong></p><p>归纳推理是从特定的实例或例子中发现一般性的规律或原理。归纳推理的结果往往是可能性的，而不是必然性的。例如，如果我看到太阳每天都从东边升起（观察的实例），我可能会推理出太阳每天都会从东边升起（一般规律）。但是，这个结论并不是必然正确的，因为这只是基于我有限的观察得出的。</p><p><strong>演绎推理与归纳推理的异同</strong></p><ul><li><p><strong>相同点</strong>：两者都是推理的方式，都是通过某种思考过程从一种信息（前提或观察）得出结论。</p></li><li><p><strong>不同点</strong>：演绎推理从一般到特殊，若前提真实，那么结论必然真实；归纳推理从特殊到一般，结论只是可能真实，并非必然真实。另外，演绎推理通常用在数学或逻辑学中，而归纳推理则更常用在科学研究中。</p></li></ul><h2 id=80演绎推理2>80演绎推理2<a hidden class=anchor aria-hidden=true href=#80演绎推理2>#</a></h2><p>解方程，从事实出发，使用逻辑步骤运算或推理，得到其它事实，这里没有推广</p><h2 id=81演绎推理3>81演绎推理3<a hidden class=anchor aria-hidden=true href=#81演绎推理3>#</a></h2><p>推导$(x+y)^=x^2+2xy+y^2$</p><p>从一个式子出发，使用逻辑步骤运算或推理，得到其它事实</p><p>演绎推理是从前提中推导出结论的推理方法。以下是一些演绎推理的例子：</p><ol><li><p>如果所有的狗都会叫，而且这只动物是一只狗，那么它一定会叫。</p></li><li><p>如果所有的人类都需要呼吸氧气，而且这个人是一个人类，那么他一定需要呼吸氧气。</p></li><li><p>如果所有蒸汽都会形成云，而且这些白色的云是蒸汽形成的，那么它们一定是蒸汽。</p></li><li><p>如果所有的矿泉水都含有矿物质，而且这瓶水是矿泉水，那么它一定含有矿物质。</p></li><li><p>如果所有的植物都需要阳光和水才能生长，而且这颗植物缺乏阳光，那么它无法正常生长。</p></li></ol><p>这些例子展示了演绎推理方法的应用，即从已知的前提中推导出结论。演绎推理可以保证结论的准确性，只要前提是真实的，结论就是正确的。在科学、数学、逻辑等领域中，演绎推理是非常重要的，因为它可以帮助我们得出精确的结论和定理。</p><h2 id=82归纳推理inductive-reasoning1>82归纳推理inductive reasoning1<a hidden class=anchor aria-hidden=true href=#82归纳推理inductive-reasoning1>#</a></h2><p>找共性</p><p>如6, 9, 12, 15……</p><h2 id=83归纳推理2>83归纳推理2<a hidden class=anchor aria-hidden=true href=#83归纳推理2>#</a></h2><p>如0, 3, 8, 15, 24,……</p><p>找规律推测第n个数是$n^2-1$</p><p>首先根据已知数据了解规律，然后推广规律，但这结果不一定正确</p><h2 id=84归纳推理3>84归纳推理3<a hidden class=anchor aria-hidden=true href=#84归纳推理3>#</a></h2><p>归纳推理是通过具体的实例来推断出一般规律或结论的推理方法。以下是一些归纳推理的例子：</p><ol><li><p>假设你已经观察到很多鸟都有羽毛，并且你还没有遇到过没有羽毛的鸟，因此你可以归纳出“所有鸟都有羽毛”这一结论。</p></li><li><p>假设你已经试着用不同的铅笔在不同的纸上写字，你发现所有的铅笔都可以写字，因此你可以归纳出“所有铅笔都可以写字”这一结论。</p></li><li><p>假设你已经观察到很多人都穿着厚外套在寒冷的天气中行走，并且你还没有遇到过不穿外套的人，因此你可以归纳出“在寒冷的天气中，人们通常穿着厚外套”这一结论。</p></li><li><p>假设你已经试着用不同的电子设备播放音乐，你发现所有的设备都可以播放音乐，因此你可以归纳出“所有电子设备都可以播放音乐”这一结论。</p></li></ol><p>这些例子说明了归纳推理方法的应用，即通过观察和实验来推断出一般规律或结论。虽然归纳推理不能保证结论的绝对准确性，但在日常生活中，它可以为我们提供很多有用的信息和指导。</p><h2 id=85-归纳规律>85 归纳规律<a hidden class=anchor aria-hidden=true href=#85-归纳规律>#</a></h2></div><footer class=post-footer><ul class=post-tags><li><a href=https://rosefinch-midsummer.github.io/zh/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/>统计学</a></li></ul><nav class=paginav><a class=prev href=https://rosefinch-midsummer.github.io/zh/posts/pastime/%E8%AE%B0%E5%BD%95%E7%89%87%E6%9C%89%E5%BA%8F%E4%B8%8E%E6%97%A0%E5%BA%8F/><span class=title>« 上一頁</span><br><span>记录片《有序与无序》</span>
</a><a class=next href=https://rosefinch-midsummer.github.io/zh/posts/pastime/%E8%AE%B0%E5%BD%95%E7%89%87%E4%B8%87%E7%89%A9%E4%B8%8E%E8%99%9A%E6%97%A0/><span class=title>下一頁 »</span><br><span>记录片《万物与虚无》</span></a></nav></footer><div><div class=pagination__title><span class=pagination__title-h style=font-size:20px>评论</span><br></div><div id=tcomment></div><script src=https://utteranc.es/client.js repo=Rosefinch-Midsummer/comments_of_blog issue-term=title theme=github-light crossorigin=anonymous async></script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.body.className.includes("dark")?"github-light":"photon-dark",t={type:"set-theme",theme:e},n=document.querySelector(".utterances-frame");n.contentWindow.postMessage(t,"https://utteranc.es")})</script></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://rosefinch-midsummer.github.io/zh/>天漢帝國復興錄</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span><div class=busuanzi-footer><span id=busuanzi_container_site_pv>本站总访问量<span id=busuanzi_value_site_pv></span>次
</span><span id=busuanzi_container_site_uv>本站访客数<span id=busuanzi_value_site_uv></span>人次</span></div></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="複製";function s(){t.innerHTML="已複製！",setTimeout(()=>{t.innerHTML="複製"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>